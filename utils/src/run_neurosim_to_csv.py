# this script collects the data generated by the script /scripts/run_neurosim.sh and puts all the results in a csv file

# the files generated by run_neurosim.sh are in the following format:
# test_date,test_time,device_name,device_id
# 19.09.2024,13:08:44,LBE247,ID300XR1000Oct
# groundWGFMU,pulseWGFMU,startVolage1,endVoltage1,startVolage2,endVoltage2,stepSize,riseTime,fallTime,pulseWidth,pulseDelay,VpreCond1,VpreCond2,riseTimePrecond,fallTimePrecon,pulseWidthPreCond,bothSides,repetitions,preConEveryLoop,groundVoltageDuringPulse,measName
# SMU2,WGFMU1,0.0,3.0,0.0,-2.0,0.1,2e-08,2e-08,0.0005,0.001,0.0,0.0,0.0001,0.0001,0.005,0.0,5.0,0.0,0.0,5e-4s-3V-m2V
# VStartPos (V),VEndPos (V),VStartNeg (V),VEndNeg (V),twidth (s),onOffRatio,A_LTP,A_LTD,num_LTP,num_LTD
# 0.1,3.0,0,-1.4,0.0005,5.662745098038989,2.4,-4.88,97,100
# NeuroSim output:
# =================
# Config read from file: /home/msc24h18/Documents/msc_project/results/test1/data/LBE247/LBE247_ID300XR1000Oct/pulsedAmplitudeSweep_DCIV_20240919130717/pulsedAmplitudeSweep_DCIV[LBE247_ID300XR1000Oct(1)]20240919130844.json
# Device type: RealDevice
# Total SubArray (synaptic core) area=5.0841e-09 m^2
# Total Neuron (neuron peripheries) area=1.2082e-09 m^2
# Total area=6.2923e-09 m^2
# Leakage power of subArrayIH is : 7.1391e-05 W
# Leakage power of subArrayHO is : 1.6238e-05 W
# Leakage power of NeuronIH is : 1.5533e-05 W
# Leakage power of NeuronHO is : 2.4850e-06 W
# Total leakage power of subArray is : 8.7629e-05 W
# Total leakage power of Neuron is : 1.8018e-05 W
# Accuracy at 1 epochs is : 18.02%
# 	Read latency=4.2509e+00 s
# 	Write latency=1.2428e+03 s
# 	Read energy=3.3233e-06 J
# 	Write energy=1.6380e-05 J
# Accuracy at 2 epochs is : 11.35%
# 	Read latency=8.5017e+00 s
# 	Write latency=1.6296e+03 s
# 	Read energy=6.6458e-06 J
# 	Write energy=2.6819e-05 J
# Accuracy at 3 epochs is ...
# ...

import os
import csv
import argparse
import numpy as np

def get_data_from_file(file, energy=False):
    with open(file, 'r') as f:
        data = f.readlines()

        d = dict()
        
        # dictionaries keep insertion order since python 3.7
        try:
            line = data[1].split(',')
            d['device_name'] = line[2]
            d['device_id'] = line[3].strip()
            d['test_date'] = line[0]
            d['test_time'] = line[1]

            keys = data[2].split(',')
            line = data[3].split(',')
            for key, val in zip(keys, line):
                d[key.strip()] = val.strip()

            keys = data[4].split(',')
            line = data[5].split(',')
            for key, val in zip(keys, line):
                d[key.strip()] = val.strip()
        except:
            print(f"Header missing in file {file}. Output will be incomplete.")

        epoch_num = []
        accuracy = []
        read_latency = []
        write_latency = []
        read_energy = []
        write_energy = []
        for line in data:
            if "Accuracy at" in line:
                match = line.strip()
                epoch_num.append(int(match.split(' ')[2]))
                accuracy.append(float(match.split(' ')[-1][:-1]))
            if "Read latency" in line:
                read_latency.append(float(line.split('=')[-1].split(' ')[0]))
            if "Write latency" in line:
                write_latency.append(float(line.split('=')[-1].split(' ')[0]))
            if "Read energy" in line:
                read_energy.append(float(line.split('=')[-1].split(' ')[0]))
            if "Write energy" in line:
                write_energy.append(float(line.split('=')[-1].split(' ')[0]))

        d['epochs'] = epoch_num[-1] if len(epoch_num) > 0 else None
        d['accuracy'] = accuracy[-1] if len(accuracy) > 0 else None

    if energy:
        return d, epoch_num, accuracy, read_latency, write_latency, read_energy, write_energy
    else:
        return d, epoch_num, accuracy


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("input", type=str, help="Path to the directory containing _output.dat files")
    parser.add_argument("output", type=str, help="Path to the output file")

    args = parser.parse_args()

    files = os.listdir(args.input)
    files = [f for f in files if f.endswith('.dat')]
    data = dict()
    for f in files:
        tmp, _, _ = get_data_from_file(os.path.join(args.input, f))
        if not data:
            data = {key: [value] for key, value in tmp.items()}
        else:
            for key, value in tmp.items():
                data[key].append(value)

    with open(args.output, 'w') as f:
        writer = csv.writer(f)
        writer.writerow(data.keys())
        writer.writerows(zip(*data.values()))
