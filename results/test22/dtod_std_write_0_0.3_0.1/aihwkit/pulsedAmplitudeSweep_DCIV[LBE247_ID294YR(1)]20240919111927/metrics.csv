epoch,train_loss,val_loss,val_acc
0.0,2.230304528236389,1.9668549267535513,0.36675
1.0,1.032071563522021,0.5881019405862118,0.8349166666666666
2.0,0.4710067471861839,0.416153093601795,0.87525
3.0,0.37201675482590996,0.353072218795089,0.8954166666666666
4.0,0.3221436436474323,0.31376833773832374,0.9074166666666666
5.0,0.287146410882473,0.28626376965102995,0.9181666666666667
6.0,0.261370299850901,0.2629969556756476,0.9219166666666667
7.0,0.23970598568518955,0.24881450063053598,0.9290833333333334
8.0,0.22394450821479162,0.23204567465693393,0.9318333333333333
9.0,0.21017499886949856,0.22225994327442444,0.9359166666666666
10.0,0.19953706076244512,0.21498053861742325,0.9375833333333333
11.0,0.1938645864377419,0.21129462657932271,0.9384166666666667
12.0,0.18846634136637053,0.20542980492749113,0.9394166666666667
13.0,0.18243609469632308,0.20164378441156858,0.9415
14.0,0.1775876999894778,0.19699569502250946,0.9418333333333333
15.0,0.17219973299155633,0.19265600579216124,0.94325
16.0,0.16772975155214467,0.18832317531663686,0.9450833333333334
17.0,0.1631194866995017,0.18280420143236506,0.9458333333333333
18.0,0.15877652395764988,0.18523368677322535,0.9434166666666667
19.0,0.15533301506439845,0.17734104252242028,0.9475833333333333
20.0,0.1519817486802737,0.1753561345543316,0.9476666666666667
21.0,0.15035940467566253,0.17441289753038833,0.9485833333333333
22.0,0.14879160922765733,0.17260862845293384,0.9495833333333333
23.0,0.14666280278066793,0.17223716856158794,0.9493333333333334
24.0,0.14519222500671944,0.1696814613694206,0.9490833333333333
