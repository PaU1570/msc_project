epoch,train_loss,val_loss,val_acc
0.0,1.4086052308877308,0.5696840642931613,0.8415833333333333
1.0,0.44692507205406823,0.3844925062136447,0.8896666666666667
2.0,0.3443025698562463,0.32934555997873877,0.90625
3.0,0.2973919112781684,0.2956054274468346,0.9141666666666667
4.0,0.2665057903031508,0.26575131250664275,0.9225
5.0,0.240435363560915,0.2480688312665579,0.9263333333333333
6.0,0.2221053074846665,0.2303650998015036,0.9316666666666666
7.0,0.2064006708363692,0.21656890035151166,0.9349166666666666
8.0,0.19270384686688583,0.2053451986904157,0.9398333333333333
9.0,0.18054678519566855,0.1940673072723315,0.94325
10.0,0.17087688269962867,0.1909259598939977,0.94375
11.0,0.1661213368549943,0.1864913298173788,0.9451666666666667
12.0,0.16088126604259015,0.18115354824731958,0.9465
13.0,0.15578198936829965,0.17724908321620303,0.9474166666666667
14.0,0.15230836022645236,0.17394984765176444,0.94875
15.0,0.14883517847458522,0.17093266431797058,0.9488333333333333
16.0,0.14531376892328263,0.16779229720618496,0.9498333333333333
17.0,0.14193863888084887,0.1650954808920939,0.9515833333333333
18.0,0.13834447686125834,0.16345348992840725,0.9510833333333333
19.0,0.1359907430509726,0.1603792899070268,0.9525
20.0,0.13278254566589992,0.15802792010908115,0.953
21.0,0.1307260020871957,0.15723460048754165,0.9529166666666666
22.0,0.12893396313736835,0.15492208026587329,0.9540833333333333
23.0,0.12738918171077968,0.15475986182610404,0.9544166666666667
24.0,0.12609224586064616,0.1538492131859381,0.9549166666666666
