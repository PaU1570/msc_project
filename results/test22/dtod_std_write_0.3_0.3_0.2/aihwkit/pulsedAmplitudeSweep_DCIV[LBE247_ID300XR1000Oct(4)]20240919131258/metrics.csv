epoch,train_loss,val_loss,val_acc
0.0,1.294343714316686,0.5144783772052602,0.85525
1.0,0.41566856706142424,0.36688000780153784,0.89425
2.0,0.3279566117028395,0.3163583297678765,0.9059166666666667
3.0,0.28536303001642227,0.2843137565366131,0.91625
4.0,0.25533180209497613,0.25921857349099,0.9241666666666667
5.0,0.23287802868088087,0.24328477676720062,0.92925
6.0,0.21344530440866946,0.2232767249199938,0.9343333333333333
7.0,0.19562883486847082,0.20997633923717002,0.9389166666666666
8.0,0.18147646654893954,0.197220622561872,0.94125
9.0,0.1684490696489811,0.18577448458985446,0.9459166666666666
10.0,0.15876775827010473,0.1814120169332687,0.9466666666666667
11.0,0.1545307256480058,0.17783260723932626,0.9474166666666667
12.0,0.15022499947001536,0.17497920948377949,0.9486666666666667
13.0,0.14605810597290594,0.16961661153572036,0.95025
14.0,0.14117078780879577,0.1663794236931395,0.9525833333333333
15.0,0.1378681433449189,0.1628339301715506,0.9534166666666667
16.0,0.13415761023263137,0.16118341208772458,0.953
17.0,0.13064728738367556,0.15720262045555927,0.9545
18.0,0.12670461315910023,0.15593619071977569,0.95425
19.0,0.12284530212730169,0.15058972256535547,0.9551666666666667
20.0,0.11954640846947828,0.1494606275388852,0.9556666666666667
21.0,0.11764826276898384,0.14732983020788176,0.9564166666666667
22.0,0.1160652071038882,0.14659065903818352,0.95725
23.0,0.11513891177376111,0.14580010247238456,0.9571666666666667
24.0,0.11379139707734187,0.1443514422751329,0.9571666666666667
