epoch,train_loss,val_loss,val_acc
0.0,1.0681888179381689,0.49454235253815954,0.8640833333333333
1.0,0.40573641326030097,0.3650749691147753,0.8945
2.0,0.32572007639209427,0.31528594697568013,0.90875
3.0,0.286930879453818,0.2858475826759922,0.91825
4.0,0.2567875300645828,0.26070881551726066,0.9251666666666667
5.0,0.23074916164080303,0.23558514299703406,0.9325833333333333
6.0,0.21168338477611542,0.21628112504456906,0.9376666666666666
7.0,0.19339512463907402,0.20569056331952837,0.9399166666666666
8.0,0.1790947498778502,0.1897688844300648,0.9444166666666667
9.0,0.1661605190585057,0.17681890585400323,0.9479166666666666
10.0,0.15553329040606817,0.17245335460818828,0.9483333333333334
11.0,0.15110137066990137,0.1669825877835776,0.9503333333333334
12.0,0.14542752350121738,0.16159133476383508,0.9515
13.0,0.14016268349687258,0.1578346813256119,0.9524166666666667
14.0,0.13549033445616562,0.15281592000355113,0.9545833333333333
15.0,0.13147094699988762,0.14936607457855913,0.9554166666666667
16.0,0.12738896999756494,0.14631101819983822,0.9565
17.0,0.12386189063141743,0.14367419647726606,0.9566666666666667
18.0,0.12076967009281118,0.1420885384122425,0.9568333333333333
19.0,0.11763937930762768,0.13916411753149427,0.9578333333333333
20.0,0.11488606621325016,0.13792607772778323,0.9591666666666666
21.0,0.11371562985579173,0.13605313332989177,0.9588333333333333
22.0,0.11176861309508483,0.13554569743969974,0.9585
23.0,0.11043543232729038,0.1333650971980805,0.95975
24.0,0.10900729407121738,0.13296566721289715,0.9605
