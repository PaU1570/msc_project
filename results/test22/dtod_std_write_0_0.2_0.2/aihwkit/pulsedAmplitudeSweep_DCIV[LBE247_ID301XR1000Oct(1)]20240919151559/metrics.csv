epoch,train_loss,val_loss,val_acc
0.0,1.1352004983822506,0.4694077581801313,0.8661666666666666
1.0,0.3850924221972624,0.34315755824617883,0.8991666666666667
2.0,0.30443953910470006,0.2931028690902477,0.9155
3.0,0.2638528094639381,0.2610885888496612,0.9261666666666667
4.0,0.23433113109072048,0.23903772104135218,0.9315833333333333
5.0,0.2119533170312643,0.2209426590459461,0.9344166666666667
6.0,0.19226786503692467,0.20436629906613776,0.9393333333333334
7.0,0.17282285955548288,0.18901338101305226,0.94425
8.0,0.15880438811083636,0.1755573074828754,0.9490833333333333
9.0,0.14585052542885144,0.16508493469433583,0.9523333333333334
10.0,0.1357355152107775,0.15999288672700207,0.9533333333333334
11.0,0.13111511173844337,0.15641051782493262,0.9538333333333333
12.0,0.12642162643869717,0.1542886929447822,0.95425
13.0,0.12256745242079099,0.15054581971204978,0.9561666666666667
14.0,0.11810301690300305,0.1463714984859875,0.9555833333333333
15.0,0.11420782271151741,0.14245296932479484,0.9573333333333334
16.0,0.1104313254567484,0.1393542602519564,0.9575833333333333
17.0,0.10709276088699698,0.137523764427355,0.9583333333333334
18.0,0.10389018765588602,0.1353493294024721,0.9586666666666667
19.0,0.10033436974510551,0.13286693831113108,0.9601666666666666
20.0,0.09762970947350065,0.13074913254364373,0.9599166666666666
21.0,0.09597771292428176,0.13011846839985314,0.9600833333333333
22.0,0.0949965356613199,0.13009502710972695,0.9598333333333333
23.0,0.09363825514291724,0.12789112515747547,0.9608333333333333
24.0,0.09222033375749986,0.1268717482329366,0.9605833333333333
