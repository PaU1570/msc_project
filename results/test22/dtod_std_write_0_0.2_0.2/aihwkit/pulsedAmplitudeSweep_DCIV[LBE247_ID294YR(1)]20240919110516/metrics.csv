epoch,train_loss,val_loss,val_acc
0.0,0.979186946729819,0.40249525826979193,0.8826666666666667
1.0,0.33829901882012686,0.30573706792548616,0.9098333333333334
2.0,0.27099094637235005,0.26470787518043465,0.924
3.0,0.23069152210156124,0.2336430646320607,0.9300833333333334
4.0,0.20233352640767893,0.20857655799927863,0.9376666666666666
5.0,0.17962245075404645,0.19063233582184036,0.94275
6.0,0.16036790211498736,0.17329064851745646,0.9493333333333334
7.0,0.14555800179888806,0.16301790965681381,0.9521666666666667
8.0,0.1317878498757879,0.15018639167612222,0.9564166666666667
9.0,0.12089013789594173,0.14205997476869442,0.9576666666666667
10.0,0.11108357189098994,0.13686496121412578,0.95975
11.0,0.10654848206043244,0.13334212571065476,0.9606666666666667
12.0,0.10287829371293386,0.1313946309519258,0.9605833333333333
13.0,0.09867202533905704,0.1270149176682722,0.9620833333333333
14.0,0.09502553465217352,0.12368723755068284,0.9631666666666666
15.0,0.09125273358821868,0.12074763038532531,0.963
16.0,0.08718446901068092,0.11870608265273908,0.96525
17.0,0.083734629979978,0.1174293459551607,0.96525
18.0,0.08036732277398308,0.11424348051065301,0.96675
19.0,0.07762648365274072,0.11336250723082017,0.9671666666666666
20.0,0.07467551818862557,0.11162898214930232,0.9675
21.0,0.07381170994912585,0.11055304227456292,0.9679166666666666
22.0,0.07262022216555973,0.11093137239878799,0.9676666666666667
23.0,0.07097758540759484,0.10892173177760808,0.9680833333333333
24.0,0.06952060843445361,0.10821702220833841,0.9685833333333334
