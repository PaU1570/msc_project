epoch,train_loss,val_loss,val_acc
0.0,2.2325581356684365,1.9815884460794164,0.40075
1.0,1.0334788676699003,0.5534439281897342,0.844
2.0,0.45761499269803363,0.40344994745038926,0.8811666666666667
3.0,0.361036707063516,0.3418237398913566,0.9001666666666667
4.0,0.3154973946809769,0.31364592545210046,0.9074166666666666
5.0,0.28112578856945036,0.2825657990860178,0.9158333333333334
6.0,0.2542569232583046,0.26266872252714124,0.9250833333333334
7.0,0.2320909371773402,0.24074299756358278,0.9306666666666666
8.0,0.21420002428690593,0.22453375646170784,0.9349166666666666
9.0,0.19947531605760258,0.2110170948695629,0.93875
10.0,0.1887463098913431,0.20654828888066906,0.93925
11.0,0.18274683498839536,0.20282351895374187,0.94125
12.0,0.17755155945320925,0.19721349667599228,0.943
13.0,0.1727322094142437,0.1926259952696397,0.9425833333333333
14.0,0.16833329127232233,0.18819496810356987,0.9453333333333334
15.0,0.16418946381906668,0.18466768164108407,0.9455833333333333
16.0,0.1606160525927941,0.18228391888848644,0.94625
17.0,0.15683822631835936,0.1777951174039156,0.9486666666666667
18.0,0.15283749153713386,0.17609185101266236,0.9489166666666666
19.0,0.1494548299262921,0.17194013158850213,0.949
20.0,0.1465787207633257,0.17067147087939877,0.95
21.0,0.14561779520412285,0.16957878981261176,0.9516666666666667
22.0,0.14400864620506765,0.16858880120785313,0.9500833333333333
23.0,0.1426673619473974,0.16739871800738446,0.9516666666666667
24.0,0.14122844104717175,0.16658988896202534,0.9514166666666667
