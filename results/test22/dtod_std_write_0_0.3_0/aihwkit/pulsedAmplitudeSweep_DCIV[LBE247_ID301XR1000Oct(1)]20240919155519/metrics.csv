epoch,train_loss,val_loss,val_acc
0.0,2.2012413536707562,1.2812731145544256,0.5715
1.0,0.6466489535768827,0.4246684411897304,0.8784166666666666
2.0,0.361882939795653,0.3333616977993478,0.90425
3.0,0.29340788687268893,0.28356652052954157,0.9185
4.0,0.25038703604539236,0.2495580984953236,0.9283333333333333
5.0,0.21983085654179255,0.2264824676466115,0.93375
6.0,0.19582933649917444,0.20680225016351075,0.9396666666666667
7.0,0.176129181774954,0.1888885861262679,0.9446666666666667
8.0,0.15916180585324763,0.17723091194366522,0.9491666666666667
9.0,0.14549678793549536,0.16920435343413276,0.9508333333333333
10.0,0.135485631848375,0.16149310666592198,0.9543333333333334
11.0,0.13146554584801198,0.1569663539647739,0.9543333333333334
12.0,0.12620746269077063,0.15353393798416598,0.9566666666666667
13.0,0.12189589123179516,0.15131335124928266,0.9569166666666666
14.0,0.1171144174511234,0.14719109273852504,0.95875
15.0,0.11344143137211601,0.1428396674467528,0.9601666666666666
16.0,0.10909014956404765,0.13911599521227974,0.9604166666666667
17.0,0.1055549136971434,0.13785662878542504,0.9606666666666667
18.0,0.1023767479310433,0.13547861028185232,0.9616666666666667
19.0,0.09867778401076793,0.13213854020540702,0.96225
20.0,0.09563702403008938,0.1311840826566232,0.9625833333333333
21.0,0.0946822228183349,0.13014422961451272,0.9635
22.0,0.09294294292479753,0.12957261625598085,0.9634166666666667
23.0,0.09164311132207513,0.12762014913630296,0.9644166666666667
24.0,0.09016995827605327,0.12765008245812767,0.9625
