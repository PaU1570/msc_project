epoch,train_loss,val_loss,val_acc
0.0,1.1028883581558864,0.5082653233028472,0.8575833333333334
1.0,0.42692100755373635,0.37975891521002386,0.8888333333333334
2.0,0.3389217127263546,0.32623148233966626,0.9055833333333333
3.0,0.2941443790793419,0.2929807864525851,0.9161666666666667
4.0,0.26546752599875134,0.267393475913621,0.9231666666666667
5.0,0.24077286092440287,0.24822187277072288,0.9285
6.0,0.220481116309762,0.2305465642996925,0.933
7.0,0.20463177417715392,0.21614708664252402,0.9378333333333333
8.0,0.18960828935354948,0.20259147656566284,0.9418333333333333
9.0,0.17686555927991868,0.1944283105908556,0.9449166666666666
10.0,0.16735143632193406,0.18889219345564537,0.9443333333333334
11.0,0.16344950055082638,0.18413461909252912,0.9459166666666666
12.0,0.15850004398574433,0.17877357371864802,0.94725
13.0,0.15415402535100778,0.17573123559989828,0.9471666666666667
14.0,0.15008797131478788,0.1748143971323016,0.9468333333333333
15.0,0.14662935047596692,0.1704661577662572,0.9486666666666667
16.0,0.14158513179421425,0.1653418528669058,0.9499166666666666
17.0,0.1378564374347528,0.16221336089074612,0.9518333333333333
18.0,0.13403930410991113,0.15952661223313275,0.9513333333333334
19.0,0.13105600922803085,0.15521686173420637,0.95275
20.0,0.12805904063085716,0.15374635932768912,0.9533333333333334
21.0,0.12661363222201666,0.15294471559451617,0.95375
22.0,0.12494968964159489,0.1523740138026311,0.9531666666666667
23.0,0.12373567250122626,0.15206710377985494,0.9525
24.0,0.1220065214758118,0.14946793564694358,0.9543333333333334
