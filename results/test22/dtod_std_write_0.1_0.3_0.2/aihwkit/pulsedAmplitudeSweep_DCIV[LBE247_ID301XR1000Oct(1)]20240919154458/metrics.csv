epoch,train_loss,val_loss,val_acc
0.0,1.0651678712566695,0.4258655738481816,0.8781666666666667
1.0,0.35509780743718145,0.3257177860892199,0.9035
2.0,0.2893859976828098,0.28657238221073406,0.9171666666666667
3.0,0.25136285155514876,0.25214314884803396,0.9248333333333333
4.0,0.22141564493378005,0.22820853077350778,0.93275
5.0,0.1988166940708955,0.2086605692599365,0.9378333333333333
6.0,0.1771289229343335,0.1880312790460092,0.9445833333333333
7.0,0.1597764753252268,0.1755300469181322,0.94875
8.0,0.1452044084519148,0.1635728306434256,0.9520833333333333
9.0,0.13090765045583247,0.15363718789229366,0.9545
10.0,0.12153878027821581,0.1480966764799458,0.9554166666666667
11.0,0.11712182910492022,0.14417249048525033,0.95725
12.0,0.11238994247093796,0.1406757378990346,0.95775
13.0,0.10858905507872502,0.13725482415843834,0.95975
14.0,0.10434265968576073,0.13400956842691658,0.9611666666666666
15.0,0.1007799763729175,0.13044184428501002,0.9611666666666666
16.0,0.09632026455613474,0.12863798948757826,0.962
17.0,0.09313362479954958,0.1270993551378079,0.96275
18.0,0.08975399739419421,0.1232314210167115,0.9643333333333334
19.0,0.08622679056351383,0.12051914664025003,0.9648333333333333
20.0,0.08347417424495021,0.11961234370840991,0.9645
21.0,0.08221728520592053,0.1196377875204099,0.9651666666666666
22.0,0.08129212450236083,0.11885816961566502,0.965
23.0,0.07971661207452417,0.11827057780341264,0.9659166666666666
24.0,0.07874558396885792,0.11642716574343911,0.9651666666666666
