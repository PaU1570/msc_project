epoch,train_loss,val_loss,val_acc
0.0,1.9365882113774617,0.789862241833768,0.7816666666666666
1.0,0.5205916972557704,0.4060087835693613,0.8815833333333334
2.0,0.3516874182422956,0.32819050491014695,0.9044166666666666
3.0,0.2919332349052032,0.2856530151627165,0.9169166666666667
4.0,0.25537227201461793,0.25781539883068266,0.9223333333333333
5.0,0.2253350558752815,0.2320222251830583,0.93025
6.0,0.20320605350037416,0.21284942657865108,0.9385833333333333
7.0,0.18564883781969546,0.19942451886674192,0.9419166666666666
8.0,0.17001065025726955,0.18576261290210358,0.9454166666666667
9.0,0.1569680602500836,0.17411826204191497,0.9483333333333334
10.0,0.14776678978155056,0.1691758403990497,0.9506666666666667
11.0,0.14236060187965632,0.1633509687801942,0.953
12.0,0.1375438886632522,0.15920175225573016,0.9540833333333333
13.0,0.132684116649131,0.15726478883322884,0.9543333333333334
14.0,0.12860263148198525,0.1523441876225332,0.9558333333333333
15.0,0.12460859957958262,0.1494371207391328,0.9568333333333333
16.0,0.12134337464223305,0.14590451917908293,0.9580833333333333
17.0,0.11719678092996279,0.14217964123855245,0.959
18.0,0.11390139665082097,0.1385484941779299,0.96025
19.0,0.11080559146155913,0.13789070805812137,0.9596666666666667
20.0,0.10825799963871638,0.13552118318670608,0.9606666666666667
21.0,0.10689219575872023,0.13459624068692644,0.9615
22.0,0.10562897066771984,0.13364934217818875,0.9613333333333334
23.0,0.10365671392902732,0.1325262499715578,0.9618333333333333
24.0,0.10264261059338847,0.13054243272091162,0.9620833333333333
