epoch,train_loss,val_loss,val_acc
0.0,0.8061512555281322,0.3928869180381298,0.8829166666666667
1.0,0.32999761018157003,0.304771659063532,0.9103333333333333
2.0,0.2664250202377637,0.2598937755014668,0.9225833333333333
3.0,0.2262276907513539,0.2419007941287883,0.9288333333333333
4.0,0.19641564994553726,0.20573195175049788,0.9389166666666666
5.0,0.17529113380114236,0.18654354842023013,0.9458333333333333
6.0,0.15781237634271383,0.1728376716058305,0.9475833333333333
7.0,0.14263996866345405,0.1655486501317392,0.9503333333333334
8.0,0.13043917823831241,0.15205941527606326,0.9548333333333333
9.0,0.11977633280555407,0.14511407150867137,0.9558333333333333
10.0,0.11116066873197754,0.14049104428751039,0.95725
11.0,0.1065870753377676,0.13619507215124496,0.9590833333333333
12.0,0.10236469129224618,0.1336586666392519,0.9594166666666667
13.0,0.09830058530966441,0.13108563046664634,0.9604166666666667
14.0,0.09462571974595388,0.1281919899951429,0.9605833333333333
15.0,0.09076210267469287,0.12409340549617055,0.9631666666666666
16.0,0.08788282956803839,0.12455125072812463,0.9625
17.0,0.08452076549455524,0.12182968694399646,0.96375
18.0,0.08200563587248326,0.11967319749454235,0.9649166666666666
19.0,0.07962980480554203,0.11761743768534445,0.9651666666666666
20.0,0.07677578056479493,0.11692735707347697,0.9655833333333333
21.0,0.07583526353972654,0.11522612434395767,0.9659166666666666
22.0,0.07448332165305813,0.1144505860977509,0.9663333333333334
23.0,0.07311856588721276,0.11464921857646489,0.9654166666666667
24.0,0.07238133457861841,0.11285514411258887,0.966
