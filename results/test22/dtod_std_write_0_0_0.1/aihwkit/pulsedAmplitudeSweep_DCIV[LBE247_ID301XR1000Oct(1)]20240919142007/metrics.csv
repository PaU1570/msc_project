epoch,train_loss,val_loss,val_acc
0.0,2.2644968264897662,2.136319729876011,0.26108333333333333
1.0,1.3504374270041783,0.7145877436120459,0.804
2.0,0.5556950842936834,0.46898122456796626,0.8648333333333333
3.0,0.41391237767537437,0.38677129070175453,0.8880833333333333
4.0,0.34584465909004214,0.3366354534679905,0.9024166666666666
5.0,0.3050972221096357,0.3051398818559469,0.91
6.0,0.27575532561540606,0.28005565857475107,0.9173333333333333
7.0,0.25293347079555195,0.2609176157399061,0.9243333333333333
8.0,0.23516402420401572,0.24815670460304048,0.9276666666666666
9.0,0.2222350282818079,0.23724447182835418,0.9308333333333333
10.0,0.21102031537393728,0.2342726716256522,0.9324166666666667
11.0,0.20654922816157342,0.22430684690938352,0.9369166666666666
12.0,0.20069453166921933,0.22006600663224432,0.9359166666666666
13.0,0.19549307005107402,0.21545776566292377,0.9365
14.0,0.19144438031812508,0.21015485816020915,0.9388333333333333
15.0,0.18598794944087665,0.20613983342859973,0.9400833333333334
16.0,0.18108088427285354,0.20229945280291933,0.9416666666666667
17.0,0.17670061516265073,0.19862298516834037,0.94275
18.0,0.17207996669908365,0.19423882550302338,0.9428333333333333
19.0,0.16828263921290637,0.18933898789134432,0.9454166666666667
20.0,0.16505802758038043,0.1875526323280436,0.9454166666666667
21.0,0.16309460988640787,0.18579096620545743,0.9439166666666666
22.0,0.16117653820166986,0.1846446170015855,0.9456666666666667
23.0,0.15960920101900897,0.18236984574097267,0.9454166666666667
24.0,0.15779587887227536,0.1816217319920976,0.9455
