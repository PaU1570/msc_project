epoch,train_loss,val_loss,val_acc
0.0,0.9223909935752551,0.42972899791091046,0.8785833333333334
1.0,0.36643165604273475,0.3414485122849967,0.90125
2.0,0.29879178725679717,0.2891198456921476,0.9171666666666667
3.0,0.2598915738364061,0.26224986638160463,0.9235
4.0,0.2336005213956038,0.2411416598813648,0.9305
5.0,0.2081064689109723,0.21781508095483196,0.9376666666666666
6.0,0.18990359809497992,0.19956047941950408,0.9414166666666667
7.0,0.17288804615288972,0.18534761837663802,0.9438333333333333
8.0,0.15921619211634,0.17792472889290212,0.9480833333333333
9.0,0.14812064227710167,0.1694854800292152,0.9509166666666666
10.0,0.13765308279792468,0.15946835846184415,0.9513333333333334
11.0,0.1324648657788833,0.1560189967895759,0.9536666666666667
12.0,0.12795226651678482,0.15496101692081132,0.9533333333333334
13.0,0.12379662544528643,0.15106279601125008,0.9546666666666667
14.0,0.1186199688265721,0.14597907845683872,0.9561666666666667
15.0,0.11621389209727447,0.1444219760794906,0.9565833333333333
16.0,0.11231853067378203,0.140011073882751,0.9579166666666666
17.0,0.10914399370675286,0.13764751375593404,0.9583333333333334
18.0,0.10586155614505212,0.13635510273594806,0.9599166666666666
19.0,0.10323557854940493,0.1342058919290913,0.9591666666666666
20.0,0.09976973668485879,0.13039345290274063,0.9605833333333333
21.0,0.09858234052856764,0.12994434428896676,0.95975
22.0,0.09718351360658804,0.12892204031665275,0.9606666666666667
23.0,0.09550464657694101,0.12722735607283228,0.9621666666666666
24.0,0.09448521449044346,0.12670503655805232,0.9615
