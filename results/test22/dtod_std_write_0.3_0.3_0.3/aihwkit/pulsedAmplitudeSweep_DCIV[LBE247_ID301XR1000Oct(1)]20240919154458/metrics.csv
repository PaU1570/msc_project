epoch,train_loss,val_loss,val_acc
0.0,0.847292219499747,0.39741163320363837,0.8846666666666667
1.0,0.34130439351995784,0.31250655575794106,0.9089166666666667
2.0,0.28250399138530097,0.2746257939316491,0.92125
3.0,0.24200660580396652,0.24628371642308033,0.9279166666666666
4.0,0.21456441913048427,0.2185676377662953,0.9339166666666666
5.0,0.19023858591914178,0.19962298967182002,0.9415833333333333
6.0,0.1727664241939783,0.1890277739495356,0.9435833333333333
7.0,0.1569786580701669,0.17398937030675563,0.94725
8.0,0.14294235861301421,0.16660828680354864,0.95225
9.0,0.1310388637855649,0.1530231868927466,0.9525
10.0,0.11965276518960793,0.14815738950756954,0.9548333333333333
11.0,0.11525852205107609,0.14306806497513613,0.9574166666666667
12.0,0.11136075976242622,0.14149986037072984,0.9576666666666667
13.0,0.10732182500511409,0.13795730173389645,0.95925
14.0,0.10408079283187786,0.13405009552321218,0.9591666666666666
15.0,0.09960989452898503,0.1311147428672523,0.9621666666666666
16.0,0.09628774756814043,0.1262136889284754,0.9616666666666667
17.0,0.09260181882108251,0.12556102325981286,0.9636666666666667
18.0,0.0897566697212557,0.12362801663062357,0.9643333333333334
19.0,0.08696434347828229,0.12243585186475452,0.9634166666666667
20.0,0.08417508491625389,0.12127257798838013,0.9645
21.0,0.08302481480315328,0.12068575851500352,0.963
22.0,0.08165666131675244,0.1181333442813063,0.9655
23.0,0.08038056891659895,0.11810259665164383,0.965
24.0,0.07915567690134048,0.1173414407010646,0.9655
