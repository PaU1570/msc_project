epoch,train_loss,val_loss,val_acc
0.0,2.3049639169375102,1.9573388385011794,0.4831666666666667
1.0,0.7603495618899663,0.4234580025869481,0.88
2.0,0.35659847962856295,0.3224637605883974,0.9059166666666667
3.0,0.28327455919981004,0.2714775466221444,0.9206666666666666
4.0,0.23757521414756774,0.2397269171048352,0.9298333333333333
5.0,0.20664363137384256,0.21419118796574307,0.9371666666666667
6.0,0.18328321951627732,0.1954281808451769,0.9419166666666666
7.0,0.16345656041055917,0.17990764226526657,0.9476666666666667
8.0,0.14813760542869567,0.1690248510740856,0.9521666666666667
9.0,0.13567889909694592,0.160062772102971,0.95325
10.0,0.12550359870741765,0.15475461598327186,0.9549166666666666
11.0,0.12091003513336182,0.1504673399823777,0.9556666666666667
12.0,0.11627496137966713,0.1481366397892224,0.9555833333333333
13.0,0.11161846935500701,0.14388068130319107,0.9571666666666667
14.0,0.10786792935182651,0.14047245430621377,0.9575833333333333
15.0,0.10375624636312326,0.13842523918348423,0.95825
16.0,0.09988661750902732,0.1350505079063488,0.9601666666666666
17.0,0.09650171609719595,0.13239391549351684,0.9604166666666667
18.0,0.0932225674862663,0.13005863740406137,0.9623333333333334
19.0,0.09001664146656792,0.12806098326604734,0.9626666666666667
20.0,0.08691260399172704,0.12816572866026074,0.9616666666666667
21.0,0.08577439296990633,0.1260348596867729,0.9625
22.0,0.08449221242467563,0.12497002939059537,0.9628333333333333
23.0,0.08301398763557274,0.12464265138941243,0.9628333333333333
24.0,0.0815964548078676,0.12406972428149682,0.9625
