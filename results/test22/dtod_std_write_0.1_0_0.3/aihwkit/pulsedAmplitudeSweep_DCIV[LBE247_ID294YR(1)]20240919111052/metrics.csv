epoch,train_loss,val_loss,val_acc
0.0,1.1709680066506067,0.5613737126931231,0.8458333333333333
1.0,0.46655742835998537,0.41604899971726095,0.8841666666666667
2.0,0.37302473280827203,0.3620272381033035,0.8970833333333333
3.0,0.3275206834177176,0.32122874870262247,0.9059166666666667
4.0,0.29195819260676703,0.2934916955121654,0.913
5.0,0.2671125476459662,0.27672841035305185,0.9180833333333334
6.0,0.24745424796144166,0.2567131791184557,0.924
7.0,0.23105654360850653,0.24389278520136437,0.9284166666666667
8.0,0.2162846527546644,0.2307583831964021,0.9309166666666666
9.0,0.20191890404125054,0.21759586234359032,0.9359166666666666
10.0,0.19173479183018208,0.21136818013768247,0.9373333333333334
11.0,0.18639560176432132,0.2058117998407242,0.9376666666666666
12.0,0.18215421221653622,0.20104434743444335,0.9396666666666667
13.0,0.17715154438465833,0.19700525469206115,0.94125
14.0,0.17232148059209187,0.19322642202469262,0.9431666666666667
15.0,0.16763119040926297,0.1890624990250836,0.9446666666666667
16.0,0.16315316453576087,0.18342623548542566,0.9464166666666667
17.0,0.1577939895639817,0.18074449441058837,0.94575
18.0,0.15489501820504664,0.17829430739375504,0.9466666666666667
19.0,0.15172719567020734,0.17596906774300844,0.9471666666666667
20.0,0.14883565536638102,0.17424181876505943,0.9493333333333334
21.0,0.14712853668630124,0.1734851633020221,0.9484166666666667
22.0,0.14631160055597622,0.174151960918878,0.94875
23.0,0.14500029225647448,0.17242322893852882,0.9488333333333333
24.0,0.14324452385803063,0.17123265938952248,0.9495
