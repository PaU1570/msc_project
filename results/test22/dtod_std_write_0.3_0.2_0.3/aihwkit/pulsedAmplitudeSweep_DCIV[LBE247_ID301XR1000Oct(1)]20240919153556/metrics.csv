epoch,train_loss,val_loss,val_acc
0.0,0.9628057919740677,0.47656927241923963,0.8660833333333333
1.0,0.3917892976005872,0.35820356241249024,0.8970833333333333
2.0,0.31761067862312,0.31006103607409813,0.9076666666666666
3.0,0.279497267305851,0.28329949136427107,0.91875
4.0,0.2517899762491385,0.25622647596483533,0.9256666666666666
5.0,0.22958826756477355,0.23711997904676071,0.9304166666666667
6.0,0.21122137181460857,0.22415405464299182,0.9355
7.0,0.19478642337024213,0.20805906876921654,0.9396666666666667
8.0,0.1786365489413341,0.1913506110060088,0.94525
9.0,0.16474198866387207,0.18205803252281028,0.9476666666666667
10.0,0.1548962645828724,0.17628850932530266,0.9479166666666666
11.0,0.15094033388545117,0.17217810119086124,0.9504166666666667
12.0,0.14568836386501788,0.16868743431219396,0.9505
13.0,0.14188374749819438,0.1644761789827905,0.9518333333333333
14.0,0.13761869430045287,0.1624140382962341,0.9523333333333334
15.0,0.13355975321431954,0.15853355095741598,0.954
16.0,0.1300289723475774,0.15601061072517583,0.9544166666666667
17.0,0.12639371043692033,0.15115583630556123,0.9559166666666666
18.0,0.1233075072541833,0.15146003505016895,0.9551666666666667
19.0,0.11959817285090685,0.14766952022910118,0.9551666666666667
20.0,0.11738138650357723,0.14633286728503855,0.9576666666666667
21.0,0.1157903823753198,0.14543022001360326,0.9569166666666666
22.0,0.11451632768660784,0.14391743687001315,0.95825
23.0,0.11246482775981227,0.14258219867429517,0.9574166666666667
24.0,0.11039978936687111,0.14227218640611528,0.95675
