epoch,train_loss,val_loss,val_acc
0.0,0.9268894171516101,0.4418731678990608,0.8671666666666666
1.0,0.36468353192011516,0.33205279279896555,0.9034166666666666
2.0,0.2973484282890956,0.2932143052445447,0.9149166666666667
3.0,0.25865151383479434,0.2602955046248563,0.9245833333333333
4.0,0.2289166744450728,0.23606891137488345,0.93175
5.0,0.20655912825961908,0.2145212377481004,0.9355833333333333
6.0,0.1878808149298032,0.1991304671193691,0.9415
7.0,0.17435479504366716,0.18847703452202233,0.9455
8.0,0.1598956716929873,0.17903372488836658,0.9469166666666666
9.0,0.1471127743050456,0.16589465622413666,0.9528333333333333
10.0,0.13734369565546511,0.16134077449269751,0.9533333333333334
11.0,0.13274327096343042,0.1554638415654289,0.95525
12.0,0.12842351346462966,0.15331354786820234,0.9555833333333333
13.0,0.12531731906781593,0.15176385547965765,0.9565833333333333
14.0,0.12102885200579962,0.14668013142580363,0.9574166666666667
15.0,0.11718716098864873,0.14379512754447282,0.9578333333333333
16.0,0.11330754485726356,0.14141575784045965,0.9579166666666666
17.0,0.10970814825842778,0.1386576775025497,0.9593333333333334
18.0,0.10611621780445178,0.13627385571004547,0.9598333333333333
19.0,0.10308157952626547,0.13256242794004527,0.9609166666666666
20.0,0.1001677376665175,0.13189343450234292,0.9604166666666667
21.0,0.09944528139506777,0.13110759712636788,0.9609166666666666
22.0,0.09770236502587795,0.12993598020972408,0.9606666666666667
23.0,0.09654279201974471,0.12916138744417657,0.9611666666666666
24.0,0.09512062907715639,0.1276960932709118,0.9615833333333333
