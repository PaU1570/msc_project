epoch,train_loss,val_loss,val_acc
0.0,2.1234097525278726,1.1929287441233372,0.6680833333333334
1.0,0.6422201191782951,0.4584800877628174,0.8709166666666667
2.0,0.39430635633071265,0.3621348204447868,0.8923333333333333
3.0,0.32186064581076307,0.3060887822128357,0.9099166666666667
4.0,0.2787942868769169,0.27623634587260004,0.92
5.0,0.24952107891440392,0.2515752717773331,0.9241666666666667
6.0,0.22521160598595938,0.22992359121587683,0.9299166666666666
7.0,0.20568904572725297,0.21350550572288798,0.93675
8.0,0.1904631487528483,0.19877252406737905,0.9414166666666667
9.0,0.17723733513057233,0.1894293526346062,0.9449166666666666
10.0,0.1675432692890366,0.18377002683329455,0.9464166666666667
11.0,0.16234104345490535,0.17907176866255542,0.94825
12.0,0.15743698939681053,0.17630742589368464,0.9479166666666666
13.0,0.15281473269313575,0.1715214267531608,0.9498333333333333
14.0,0.14858199027677377,0.16934714385090358,0.9496666666666667
15.0,0.14444838372369606,0.16571414591546388,0.9506666666666667
16.0,0.1403517278706034,0.16108406529306096,0.9529166666666666
17.0,0.1364594782566031,0.15932375408629787,0.9536666666666667
18.0,0.13267275863637526,0.15599402551479796,0.9538333333333333
19.0,0.12932651009907326,0.15262944308763488,0.955
20.0,0.12656132153173288,0.15148843678229668,0.9559166666666666
21.0,0.1256452910900116,0.15031595813467147,0.9558333333333333
22.0,0.12385893931488196,0.14879377023812304,0.95625
23.0,0.12254676920175553,0.14714605527672361,0.9563333333333334
24.0,0.12141765636205673,0.14605796594727546,0.95675
