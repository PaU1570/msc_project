epoch,train_loss,val_loss,val_acc
0.0,2.0841787909666696,0.9421665880908358,0.7126666666666667
1.0,0.5639898953636487,0.41145898916936935,0.8820833333333333
2.0,0.3490901190539201,0.3219331100266031,0.9060833333333334
3.0,0.281316680153211,0.27173669390538907,0.923
4.0,0.24051795178155105,0.24161610538338094,0.92975
5.0,0.20945784982045493,0.21749120166010044,0.9370833333333334
6.0,0.18549406851331393,0.20016663999078757,0.9420833333333334
7.0,0.16610512248178322,0.18411440364620152,0.9460833333333334
8.0,0.15019980308413505,0.16933263293368386,0.9515
9.0,0.1367983175367117,0.16013891182522824,0.9534166666666667
10.0,0.12672236392398675,0.1537697184830904,0.9563333333333334
11.0,0.12189010257025559,0.1503531500063044,0.9576666666666667
12.0,0.11714220501730839,0.1466255514149336,0.9575
13.0,0.11229607144743205,0.142560553063262,0.9591666666666666
14.0,0.10805402525266011,0.14008863210836622,0.9586666666666667
15.0,0.1038866836875677,0.13530658996921588,0.9598333333333333
16.0,0.10037606945385535,0.13477156929513243,0.96025
17.0,0.09621764949460825,0.1320217928868976,0.9608333333333333
18.0,0.0932401338617007,0.12822015918394986,0.962
19.0,0.08962342796474695,0.1261223622280708,0.9630833333333333
20.0,0.08693419254322847,0.12577017939629706,0.9634166666666667
21.0,0.08581445880234241,0.12374361017917065,0.9638333333333333
22.0,0.08429402894775073,0.12275069953992646,0.96375
23.0,0.08300523428743084,0.12207769552007952,0.9641666666666666
24.0,0.08210731669018666,0.12126018859921618,0.9646666666666667
