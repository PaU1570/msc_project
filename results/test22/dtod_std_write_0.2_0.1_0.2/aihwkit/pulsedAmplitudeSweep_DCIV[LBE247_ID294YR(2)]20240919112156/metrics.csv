epoch,train_loss,val_loss,val_acc
0.0,1.4124776014884313,0.5881300593944306,0.8410833333333333
1.0,0.4699382033745448,0.4073213261175663,0.8818333333333334
2.0,0.3670004937450091,0.34611534572979236,0.9033333333333333
3.0,0.31698605809609093,0.312189330168544,0.9091666666666667
4.0,0.28397007764379184,0.28330597935363333,0.9181666666666667
5.0,0.25556521222492057,0.25551946675206755,0.9265
6.0,0.23326262215773264,0.24207687290742042,0.9306666666666666
7.0,0.2165731375614802,0.22614741269895372,0.9339166666666666
8.0,0.20117564889291922,0.21439031020123908,0.9379166666666666
9.0,0.1888081381767988,0.20207758683790553,0.9424166666666667
10.0,0.17931982179979483,0.19695789055859156,0.9431666666666667
11.0,0.17373224145670732,0.18946396375193875,0.9455
12.0,0.16840692474444707,0.18555036365510302,0.9449166666666666
13.0,0.16360011796156565,0.18157857206669895,0.94675
14.0,0.15949955629805723,0.17960172622127735,0.94775
15.0,0.1546147096529603,0.17554067172347865,0.9490833333333333
16.0,0.1503418787320455,0.17111118385528631,0.9506666666666667
17.0,0.14634497013439735,0.1673149167500595,0.9515833333333333
18.0,0.14225542376438777,0.164085674832793,0.9518333333333333
19.0,0.138223295720915,0.16112538116013117,0.95325
20.0,0.13508445033679406,0.16034430326854296,0.9543333333333334
21.0,0.1331060987537106,0.15884428506994502,0.95375
22.0,0.13139429139594236,0.15784255108062892,0.9544166666666667
23.0,0.13007387927919625,0.15851479742993066,0.9536666666666667
24.0,0.1283701813593507,0.15506095659146282,0.95625
