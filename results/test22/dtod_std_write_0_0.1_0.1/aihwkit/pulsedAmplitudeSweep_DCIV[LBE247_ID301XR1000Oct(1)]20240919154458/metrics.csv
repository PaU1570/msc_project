epoch,train_loss,val_loss,val_acc
0.0,1.5692125685612361,0.5728479119691443,0.8318333333333333
1.0,0.4293841006358465,0.35992106819089426,0.8941666666666667
2.0,0.3152922055721283,0.29479472442193233,0.9135833333333333
3.0,0.26317594677209855,0.25846148916381473,0.9228333333333333
4.0,0.22836773266394933,0.22842722691278508,0.9315833333333333
5.0,0.2013865576783816,0.20865919813513756,0.9388333333333333
6.0,0.17969170862684647,0.18931702883081866,0.942
7.0,0.16237800512711206,0.1767660220688645,0.9473333333333334
8.0,0.14744895834475755,0.16354736693679017,0.9504166666666667
9.0,0.13518416730811197,0.15471132856575734,0.9539166666666666
10.0,0.12590072274953126,0.14928813883043984,0.9545
11.0,0.12171937885632117,0.1468271663253929,0.9556666666666667
12.0,0.11729451341181993,0.14201916526368957,0.95725
13.0,0.11312496962646644,0.13831941132493158,0.9581666666666667
14.0,0.10879196905344725,0.13536481440384338,0.9589166666666666
15.0,0.1054492116731902,0.13214989737706614,0.9606666666666667
16.0,0.10146653870120645,0.12879612243318178,0.9616666666666667
17.0,0.0973767937682569,0.12610233448287275,0.9626666666666667
18.0,0.09386538621783257,0.12310731799361553,0.9638333333333333
19.0,0.09031230837479234,0.12196815313097645,0.9636666666666667
20.0,0.08784591210757693,0.1205859429579466,0.9640833333333333
21.0,0.08662235392381748,0.11918841208271841,0.96475
22.0,0.08466028993328413,0.1181184129809287,0.9648333333333333
23.0,0.0839851992726326,0.1180059518863229,0.9649166666666666
24.0,0.08238539517422518,0.11683117721150531,0.9646666666666667
