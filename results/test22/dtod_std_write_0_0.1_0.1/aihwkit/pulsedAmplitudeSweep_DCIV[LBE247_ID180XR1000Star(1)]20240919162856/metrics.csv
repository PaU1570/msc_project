epoch,train_loss,val_loss,val_acc
0.0,2.1182365198135376,1.2835441631205537,0.6185
1.0,0.7107282486756643,0.4798663797530722,0.861
2.0,0.4051761205196381,0.3626962884309444,0.8953333333333333
3.0,0.3246709320048491,0.3127238678329803,0.90825
4.0,0.28207952313621837,0.2766537822862255,0.9194166666666667
5.0,0.25224626483519874,0.2523811234042366,0.9243333333333333
6.0,0.22822302094101907,0.2335623231657008,0.9313333333333333
7.0,0.21009816771745682,0.21605975668322533,0.9360833333333334
8.0,0.19371725453436375,0.20365030102511036,0.9401666666666667
9.0,0.18101299525052308,0.19258813613510511,0.9433333333333334
10.0,0.17072124025970697,0.187250408938432,0.94625
11.0,0.165776543105642,0.18219584941943276,0.9476666666666667
12.0,0.1611108286753297,0.17820049465653745,0.9493333333333334
13.0,0.15669783736765386,0.17397957806416015,0.9501666666666667
14.0,0.15201275343199572,0.1703684868172128,0.9500833333333333
15.0,0.14811095837752025,0.16692309786981724,0.9508333333333333
16.0,0.14443251608063779,0.164101185257289,0.95225
17.0,0.140081997046868,0.1627634098119241,0.9506666666666667
18.0,0.13608835348735254,0.1573779289511607,0.9540833333333333
19.0,0.132579262688756,0.15534282333039223,0.95475
20.0,0.13019804228842258,0.15260969746382314,0.9559166666666666
21.0,0.12878452493002018,0.15202231661594928,0.9565833333333333
22.0,0.12749736136446396,0.15135863231138347,0.9568333333333333
23.0,0.125700418377916,0.15010980486949074,0.9561666666666667
24.0,0.12370894142985343,0.148556097608773,0.9574166666666667
