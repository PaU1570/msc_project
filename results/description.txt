test1:
test2:
test3:
test4:
test5:
test6:
test7: Adam optimizer, alpha=0.01, beta1=0.8, beta2=0.999. Number of levels = number of points. Data badly truncated.
test8: ID301XR1000Oct 10 runs. Same optimizer params as test7.
test9: Accuracy vs nonlinearity parameter, 0 to 1 with 0.1 steps and 1 to 9 with unit steps. 3 runs.
test10: Accuravy vs number of LTP and LTD levels.
test11: Adam optimizer, same parameters as test7, 30 LTP and LTD levels for all devices. Data properly truncated.
test12: Accuracy vs number of levels (numLTP=numLTD, 5 to 20 with steps of 5) and SGD learning rate (0.25 to 1 with 0.25 step).
test13: Accuracy vs min/max conductance. ID294YR 2024.09.19 11:21:56 as reference. Adam optimizer with previous parameters.
test14: Same as test13, max conductance range from 1e-11 to 1e-10 with 1e-11 steps.
test15: aihwkit noise test. Tests done on ID301XR1000Oct 2024.09.19 14:41:43.
test16: aihwkit on all analyzed data. Noise values: default
test17: same as test16, but with SGD instead of ttv2
test18: like test16 but with more noise: { dw_min_dtod = 0.5, dw_min_std = 1.0, }
test19: aihwkit ttv2 with varying noises: { 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1 } for dw_min_dtod or dw_min_std while keeping the other at 0.3
test20: mixed precision with SGD with varying each noise parameter while keeping the others constant (at default)
test21: like test20 but a more narrow range of noises
test22: like test21 but with new fitting (rescaled dw_min, SGD lr=0.5)
test23: piecewise fit (rescaled, SGD lr=0.5) with dw_min_std=dw_min_dtod=write_noise_std=0. Weights at each epoch are saved (LBE247_analyzed_2nd_run_only)
test24: like test23 but for the new data 20241024_LBE247_analyzed_2nd_run_only
test25: like test23 using Reference Device (all references set to the same value)
test26: like test23 but with learn_out_scaling=True
test27: repeat test26 but saving the final output scaling
test28: like test23 and test26 but with Adam optimizer sweeping learning rates (0.02 to 0.4 step 0.02) and beta 1 (0.7 to 0.9 step 0.05) (both learn_out_scaling=True and False)
test29: piecewise fit (rescaled, SGD lr=0.5) mp with dw_min_std=dw_min_dtod=0.3, write_noise_std_mult sweep from 0.1 to 1 step 0.1, learn_out_scaling=True
test30: like test29 but lr=0.8

xmas run (remember to not save fit pictures):
- test31a: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: dw_min_dtod sweep (0, 0.5, step 0.05)
- test31b: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: dw_min_std sweep (0, 0.5, step 0.05)
- test31c: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: w_min_dtod sweep (0, 0.5, step 0.05)
- test31d: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: w_max_dtod sweep (0, 0.5, step 0.05)
- test31e: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.01) and (0.5, 2, step 0.1)

- test32a: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, default noise
- test32b: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=True, default noise
- test32c: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, default noise + 0.3 write_noise_std
- test32d: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=True, default noise + 0.3 write_noise_std

- test33: NeuroSim test11 but with number of states = number of pulses

- test34: NeuroSim test10 but save pulse numbers, 5 runs

- test35a: asymmetric pulsing 1up1down learn_out_scaling=False, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)
- test35b: asymmetric pulsing 1up2down learn_out_scaling=False, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)
- test35c: asymmetric pulsing 1up3down learn_out_scaling=False, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)
- test35d: asymmetric pulsing 1up1down learn_out_scaling=True, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)
- test35e: asymmetric pulsing 1up2down learn_out_scaling=True, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)
- test35f: asymmetric pulsing 1up3down learn_out_scaling=True, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.1)

- test36: repeat test31e but with learn_out_scaling=True. Sweep step 0.1 instead of 0.05; and repeat with 0.3 noise on all the other parameters.

- test37a-h: repeat test32a-d but with pulseType=None and pulseType=Stochastic

- test38: floating point model, sweep lr (0.05, 1, step 0.05) (save weights)