test1:
test2:
test3:
test4:
test5:
test6:
test7: Adam optimizer, alpha=0.01, beta1=0.8, beta2=0.999. Number of levels = number of points. Data badly truncated.
test8: ID301XR1000Oct 10 runs. Same optimizer params as test7.
test9: Accuracy vs nonlinearity parameter, 0 to 1 with 0.1 steps and 1 to 9 with unit steps. 3 runs.
    test9b: change number of states to 25.
test10: Accuravy vs number of LTP and LTD levels.
test11: Adam optimizer, same parameters as test7, 30 LTP and LTD levels for all devices. Data properly truncated.
test12: Accuracy vs number of levels (numLTP=numLTD, 5 to 20 with steps of 5) and SGD learning rate (0.25 to 1 with 0.25 step).
test13: Accuracy vs min/max conductance. ID294YR 2024.09.19 11:21:56 as reference. Adam optimizer with previous parameters.
test14: Same as test13, max conductance range from 1e-11 to 1e-10 with 1e-11 steps.
test15: aihwkit noise test. Tests done on ID301XR1000Oct 2024.09.19 14:41:43.
test16: aihwkit on all analyzed data. Noise values: default
test17: same as test16, but with SGD instead of ttv2
test18: like test16 but with more noise: { dw_min_dtod = 0.5, dw_min_std = 1.0, }
test19: aihwkit ttv2 with varying noises: { 0.3, 0.5, 0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9, 2.1 } for dw_min_dtod or dw_min_std while keeping the other at 0.3
test20: mixed precision with SGD with varying each noise parameter while keeping the others constant (at default)
test21: like test20 but a more narrow range of noises
test22: like test21 but with new fitting (rescaled dw_min, SGD lr=0.5)
test23: piecewise fit (rescaled, SGD lr=0.5) with dw_min_std=dw_min_dtod=write_noise_std=0. Weights at each epoch are saved (LBE247_analyzed_2nd_run_only)
test24: like test23 but for the new data 20241024_LBE247_analyzed_2nd_run_only
test25: like test23 using Reference Device (all references set to the same value)
test26: like test23 but with learn_out_scaling=True
test27: repeat test26 but saving the final output scaling
test28: like test23 and test26 but with Adam optimizer sweeping learning rates (0.02 to 0.4 step 0.02) and beta 1 (0.7 to 0.9 step 0.05) (both learn_out_scaling=True and False)
test29: piecewise fit (rescaled, SGD lr=0.5) mp with dw_min_std=dw_min_dtod=0.3, write_noise_std_mult sweep from 0.1 to 1 step 0.1, learn_out_scaling=True
test30: like test29 but lr=0.8

xmas run (remember to not save fit pictures):
- test31a: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: dw_min_dtod sweep (0, 0.5, step 0.05)
- test31b: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: dw_min_std sweep (0, 0.5, step 0.05)
- test31c: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: w_min_dtod sweep (0, 0.5, step 0.05)
- test31d: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: w_max_dtod sweep (0, 0.5, step 0.05)
- test31e: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, 0 noise for all except: write_noise_std sweep (0, 0.5, step 0.01) and (0.5, 2, step 0.1)

- test32a: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, default noise
- test32b: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=True, default noise
- test32c: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=False, default noise + 0.3 write_noise_std
- test32d: piecewise fit, lr=0.5, pulseType=DeterministicImplicit, learn_out_scaling=True, default noise + 0.3 write_noise_std

- test33: NeuroSim test11 but with number of states = number of pulses

- test34: NeuroSim test10 but save pulse numbers, 5 runs

- test35a: asymmetric pulsing 1up1down learn_out_scaling=False, 0 noise for all and 0.3 (default) noise for all.
- test35b: asymmetric pulsing 1up2down learn_out_scaling=False, 0 noise for all and 0.3 (default) noise for all.
#- test35c: asymmetric pulsing 1up3down learn_out_scaling=False, 0 noise for all and 0.3 (default) noise for all.
- test35d: asymmetric pulsing 1up1down learn_out_scaling=True, 0 noise for all and 0.3 (default) noise for all.
- test35e: asymmetric pulsing 1up2down learn_out_scaling=True, 0 noise for all and 0.3 (default) noise for all.
#- test35f: asymmetric pulsing 1up3down learn_out_scaling=True, 0 noise for all and 0.3 (default) noise for all.

- test36: repeat test31e but with learn_out_scaling=True. 0 and 0.3 write noise instead of sweep; and repeat with 0.3 noise on all the other parameters.

- test37a-h: repeat test32a-d but with pulseType=None and pulseType=Stochastic

- test38: floating point model, sweep lr (0.05, 1, step 0.05) (save weights)

test40: compare floating point, mixed-precision, and plain sgd for three devices (default noise):
    - ID181ZR1000,24.10.2024,12:21:13, with symmetry point 0.07
    - ID181ZR1000,24.10.2024,12:51:01, with symmetry point 0.24
    - ID181ZR1000,24.10.2024,12:44:23, with symmetry point 0.62
    - ID170ZR500,24.10.2024,13:22:32, with the lowest dw_min (0.03)

test41: ID170ZR500 13:22:32 adam lr sweep (0.01, 0.05, 0.1, 0.2, 0.4, 0.6, 1, 2) with beta1=0.8 and beta2=0.999
test42: all LBE247 files; adam 0.01/0.8/0.999; piecewise fit; learn_out_scaling=True
test43: like test42 but with improved (?) fit.
test44: write_noise_std sweep while keeping the other noises at default.
test45: mixed-precision (0 noise) with symmetric and asymmetric granularity. For symmetric, use (granularity_up + granularity_down)/2 (unfinished)
test46: test45 but counting pulses
test47: mp with symmetric threshold, use half of the granularity average. No noise.
test48: repeat test46 multiple times with 0 and 0.3 noise, but only for the devices that performed significantly different between symmetric and asymmetric on test46
test49os: check branch 'onesided'
test50: fixed piecewise fit (piecewise_up[-1] = piecewise_down[0] = 0), no noise, plain sgd with lr 0.05
test51: test50 with learn_out_scaling=True
test52: mixed-precision with fixed fit
test53: neurosim dtod noise sweep
test54: neurosim ideal device numlevel asymmetry sweep
test55: ID161ZR15000 with symmetry point shifting
test56: test55 but for all devices, lr=0.1
test57: asymmetric pulsing ID294YR 11:13:50
test58: ID161ZR15000 asymmetric pulsing
test59: ID161ZR15000 11:19:00 (sp=0.44) mixed-precision batch size and granularity sweep

TODO: asymmetric 1up2down write_noise_sweep (ID294YR)
TODO: floating point model
TODO: neurosim ideal device ctoc noise sweep
TODO: test46 with 0.3 noise
TODO: aihwkit with similar network size as neurosim