epoch,train_loss,val_loss,val_acc
0.0,2.3018484767278036,2.288925470189845,0.14375
1.0,0.7926340983907382,0.3199633182759615,0.9053333333333333
2.0,0.25050349812706313,0.22516585755696955,0.9349166666666666
3.0,0.18446936466544867,0.18662460421786664,0.9434166666666667
4.0,0.15054989925771953,0.16051517156487766,0.9534166666666667
5.0,0.1257774064478775,0.1517057367749116,0.9555833333333333
6.0,0.11113645810261369,0.1430949428604242,0.9585
7.0,0.10369109083960454,0.14808168264224808,0.9575833333333333
8.0,0.10137748584027091,0.14073196653910774,0.9588333333333333
9.0,0.09428876074279348,0.13689008031159322,0.9620833333333333
10.0,0.08945355849464734,0.13960309100258064,0.9603333333333334
11.0,0.08697327837099632,0.13373750453180772,0.96275
12.0,0.08440941904423138,0.13405318343219289,0.9633333333333334
13.0,0.0843767147132506,0.13602870510534404,0.9625
14.0,0.0857763921332856,0.13292759557333875,0.96325
15.0,0.08254284154685836,0.13460386380989184,0.9618333333333333
16.0,0.08385866727804145,0.13424807744338474,0.9616666666666667
17.0,0.08243589803762734,0.129622897581554,0.9641666666666666
18.0,0.08074845044283817,0.13641991493282246,0.9614166666666667
19.0,0.08352957206405699,0.13611301789902389,0.9638333333333333
20.0,0.08157480218013127,0.13219778445559216,0.9631666666666666
21.0,0.08043532193793605,0.13423342866070093,0.9626666666666667
22.0,0.07960411212407052,0.13104878093284417,0.96475
23.0,0.08169920726244648,0.13390069203253122,0.9639166666666666
24.0,0.08078603669938941,0.13558547439529223,0.9630833333333333
