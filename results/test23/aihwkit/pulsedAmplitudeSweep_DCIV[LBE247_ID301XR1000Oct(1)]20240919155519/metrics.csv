epoch,train_loss,val_loss,val_acc
0.0,2.2927441873550416,1.9704721164196095,0.35991666666666666
1.0,0.8354610245227814,0.43397567936397613,0.8754166666666666
2.0,0.36830508590737976,0.3321490505749875,0.903
3.0,0.2951689232587814,0.2810784547411381,0.9193333333333333
4.0,0.25070032106836637,0.24705924620812245,0.9285833333333333
5.0,0.21787884142498176,0.22317478762186588,0.9354166666666667
6.0,0.19446718342105548,0.2024671956896782,0.9418333333333333
7.0,0.17516868732869625,0.1876696384452442,0.9446666666666667
8.0,0.15955326777944961,0.1745136393670072,0.9490833333333333
9.0,0.14638892043630283,0.16501065333710707,0.95175
10.0,0.13609042116751274,0.159563271546776,0.9525
11.0,0.13224683173000812,0.15495197167818217,0.9545833333333333
12.0,0.1268839988534649,0.15047579242828044,0.9564166666666667
13.0,0.12281189630677303,0.14809783837421142,0.9563333333333334
14.0,0.11826783584306637,0.14398319989522088,0.95725
15.0,0.1139468058248361,0.1397533690398361,0.9589166666666666
16.0,0.11027790314952532,0.13842983972875678,0.9586666666666667
17.0,0.10654977631693086,0.13426434073319776,0.9604166666666667
18.0,0.10294385013232628,0.1326282888532002,0.9595833333333333
19.0,0.09954057455311219,0.1289165357841139,0.9620833333333333
20.0,0.09657087547083695,0.1271176446883127,0.962
21.0,0.09487144377206763,0.1264066544975689,0.9631666666666666
22.0,0.09363108588010073,0.12585017680527366,0.9616666666666667
23.0,0.09243593400716782,0.1242882640279354,0.9633333333333334
24.0,0.09109839669242502,0.12315448584589869,0.9631666666666666
