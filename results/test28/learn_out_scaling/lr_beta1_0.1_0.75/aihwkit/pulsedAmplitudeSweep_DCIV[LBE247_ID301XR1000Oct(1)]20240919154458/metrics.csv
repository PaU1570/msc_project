epoch,train_loss,val_loss,val_acc
0.0,2.3105889008839924,2.324097516688895,0.09975
1.0,0.683842400064071,0.2977988140142344,0.9076666666666666
2.0,0.23811680015424888,0.22666675975902917,0.9321666666666667
3.0,0.18830369871854782,0.18754129934104832,0.9436666666666667
4.0,0.15092138320704301,0.18040046083958858,0.947
5.0,0.1311935753983756,0.15748668499687252,0.9529166666666666
6.0,0.11334140323723356,0.14970089427809766,0.9576666666666667
7.0,0.09839927900768816,0.14480474120640058,0.9576666666666667
8.0,0.08941232215613126,0.14885718381884408,0.9578333333333333
9.0,0.08395385365001858,0.13832900276348153,0.961
10.0,0.0652232228104646,0.1349909593861431,0.9621666666666666
11.0,0.05920818372194966,0.13169571281252232,0.9654166666666667
12.0,0.055121054076123985,0.1347726862060223,0.9633333333333334
13.0,0.05054877035820391,0.1334194670644331,0.9640833333333333
14.0,0.04541517348121852,0.13543379015507215,0.9661666666666666
15.0,0.043710424233383185,0.13439656051613905,0.9655
16.0,0.03992177645190774,0.1400581276300611,0.9645833333333333
17.0,0.03783210516984885,0.1353922766531778,0.9661666666666666
18.0,0.035205657459485035,0.13707448496264057,0.96575
19.0,0.03256600765216475,0.150496213500601,0.9655
20.0,0.02635683220543433,0.15702225114526958,0.9671666666666666
21.0,0.02458346657451087,0.15448194720343925,0.9659166666666666
22.0,0.024638534047058784,0.14970642936872963,0.96775
23.0,0.02234372302940513,0.16813047472207976,0.9655833333333333
24.0,0.021190582052940346,0.1703086611430874,0.9663333333333334
