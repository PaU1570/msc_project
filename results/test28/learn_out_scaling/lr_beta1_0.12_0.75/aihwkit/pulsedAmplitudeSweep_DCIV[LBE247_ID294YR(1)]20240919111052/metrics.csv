epoch,train_loss,val_loss,val_acc
0.0,1.180526210943858,0.47711898021875543,0.855
1.0,0.3410660060445468,0.31288183500316546,0.9065833333333333
2.0,0.25796636044979093,0.24802303092276795,0.92775
3.0,0.2188705663854877,0.2167220042741045,0.9376666666666666
4.0,0.1912842699959874,0.20959936080381592,0.9399166666666666
5.0,0.1738530186638236,0.1937582881407852,0.9434166666666667
6.0,0.159267799825718,0.19295318232987949,0.9451666666666667
7.0,0.1480968073680997,0.1872036842619406,0.948
8.0,0.1380758328475058,0.171899778902174,0.94975
9.0,0.1307878211910526,0.16548825235680698,0.9515
10.0,0.116760601905485,0.15860556635728223,0.9531666666666667
11.0,0.11037238192309935,0.1540230719689676,0.9561666666666667
12.0,0.10732375731815895,0.1469629882349375,0.9578333333333333
13.0,0.10485040295124054,0.15089073175306808,0.9580833333333333
14.0,0.10071169472237428,0.13746041875887424,0.9605
15.0,0.09758714912521342,0.1370614935009879,0.9606666666666667
16.0,0.09493859114994606,0.14937601619439714,0.9595
17.0,0.0919951241388917,0.14084719217808403,0.962
18.0,0.08984525858517736,0.14177122977909018,0.9606666666666667
19.0,0.0867375224865973,0.14135344702492844,0.9610833333333333
20.0,0.07921777570806443,0.14227715968600216,0.9616666666666667
21.0,0.07948236441363891,0.1415888685980772,0.9618333333333333
22.0,0.07906270246456067,0.13792150041108278,0.9635
23.0,0.07631476676401992,0.14163774971731324,0.9629166666666666
24.0,0.07644300120680904,0.13939554570242763,0.96175
