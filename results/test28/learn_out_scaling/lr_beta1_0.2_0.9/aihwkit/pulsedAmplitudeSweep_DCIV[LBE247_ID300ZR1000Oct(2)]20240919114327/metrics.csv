epoch,train_loss,val_loss,val_acc
0.0,2.3167413489023843,2.3162852982257274,0.09908333333333333
1.0,2.019587790608406,0.730992927671747,0.7670833333333333
2.0,0.5566414217750232,0.44972705246603234,0.8664166666666666
3.0,0.383696103711923,0.34741571945871447,0.89425
4.0,0.3148834305902322,0.3070483418141908,0.9064166666666666
5.0,0.2734419201662143,0.2649930999317068,0.9245
6.0,0.24101234556237858,0.244164978015296,0.9286666666666666
7.0,0.22564266295731067,0.25196195068828603,0.9229166666666667
8.0,0.21040208417673906,0.24356158410615109,0.9280833333333334
9.0,0.19997634240984916,0.21588543477527639,0.93575
10.0,0.17754935030887525,0.20849703249343216,0.9396666666666667
11.0,0.16564797925949096,0.20275695188010626,0.9424166666666667
12.0,0.15749668156603971,0.1889588970770227,0.9461666666666667
13.0,0.15227040324608485,0.18634162924470418,0.9456666666666667
14.0,0.1447211898614963,0.1816695353878226,0.9460833333333334
15.0,0.1403760960412522,0.18543660996402514,0.949
16.0,0.1335536755658686,0.18369390935379457,0.9480833333333333
17.0,0.1307593979239464,0.17123524127329917,0.9523333333333334
18.0,0.12563345756630104,0.17486042833510548,0.9486666666666667
19.0,0.11957450332989296,0.16849270809263467,0.9535
20.0,0.11179023253296812,0.16615117260036952,0.9520833333333333
21.0,0.10841464798400799,0.16293664456919787,0.9534166666666667
22.0,0.10782539040626338,0.16623711632564664,0.95325
23.0,0.10439501027576625,0.162995840046317,0.9523333333333334
24.0,0.10377111440400283,0.16552531115334243,0.9541666666666667
