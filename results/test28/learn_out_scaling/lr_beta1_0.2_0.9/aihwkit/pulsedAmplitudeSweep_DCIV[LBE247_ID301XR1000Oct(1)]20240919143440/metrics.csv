epoch,train_loss,val_loss,val_acc
0.0,2.5832963105837505,2.3408028686300235,0.10016666666666667
1.0,1.995632525285085,1.0028297850426207,0.6585833333333333
2.0,0.6448478195468584,0.4714963570871252,0.854
3.0,0.4029704789817333,0.36489043785060976,0.89375
4.0,0.32686666305859885,0.31913218758207684,0.9088333333333334
5.0,0.2820660798152288,0.28728620565318047,0.9168333333333333
6.0,0.2617289920548598,0.27276399787119093,0.9180833333333334
7.0,0.2353057286615173,0.2333898163063729,0.9301666666666667
8.0,0.2164178239752849,0.22007460149123947,0.9326666666666666
9.0,0.20105418226122856,0.23198295434183897,0.9294166666666667
10.0,0.1835873739272356,0.20502802900018843,0.9385833333333333
11.0,0.172001835398376,0.20257077971473336,0.938
12.0,0.16526666804154713,0.19632756914150842,0.9408333333333333
13.0,0.15594373484452564,0.18474868209438122,0.9448333333333333
14.0,0.14994704080621402,0.18316796705364546,0.9439166666666666
15.0,0.14529111219818394,0.18095559711033044,0.9465833333333333
16.0,0.14103677881260712,0.18509462559992013,0.9469166666666666
17.0,0.136059113898625,0.17702742989987452,0.95
18.0,0.13217653572931887,0.1621049367525476,0.9510833333333333
19.0,0.12853983488306403,0.17664340613508953,0.9481666666666667
20.0,0.12072735051562389,0.15683023802975707,0.9528333333333333
21.0,0.11509421805664898,0.15489109388572422,0.95375
22.0,0.1145158551769952,0.16354544606416466,0.95075
23.0,0.11169485762901604,0.15451918529505107,0.9535
24.0,0.1114510858207941,0.1558775009309992,0.9545833333333333
