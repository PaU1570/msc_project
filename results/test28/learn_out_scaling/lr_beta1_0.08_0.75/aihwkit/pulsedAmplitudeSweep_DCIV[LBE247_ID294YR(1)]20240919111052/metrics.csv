epoch,train_loss,val_loss,val_acc
0.0,2.213877807776133,1.3331416991162808,0.5476666666666666
1.0,0.7541218528548876,0.4272985490078622,0.8715
2.0,0.3461847794850667,0.3017364493472145,0.9101666666666667
3.0,0.2669215272764365,0.28011759766872896,0.91675
4.0,0.23539870270589988,0.24367604874312243,0.9289166666666666
5.0,0.21285705116391182,0.22701999069528378,0.9338333333333333
6.0,0.19516520075003307,0.21080713520975822,0.9373333333333334
7.0,0.18108643391480048,0.20446791963532884,0.9431666666666667
8.0,0.16751636423170566,0.1976806079433795,0.9424166666666667
9.0,0.1606019522473216,0.18603670837833208,0.945
10.0,0.1481234411622087,0.17954772291705012,0.947
11.0,0.1401308812883993,0.17800726497823255,0.9476666666666667
12.0,0.13552043208728234,0.17086450896285316,0.9490833333333333
13.0,0.13359620402877528,0.1695045740640861,0.95
14.0,0.13110978262561063,0.1673208772442601,0.9509166666666666
15.0,0.12955752887576819,0.1634567891584432,0.9520833333333333
16.0,0.12637779433776936,0.16951564902518976,0.9515
17.0,0.12278265728304784,0.16099428785766692,0.9525
18.0,0.1196941890331606,0.15923537078135191,0.9526666666666667
19.0,0.11635227305038522,0.15849233514312258,0.9539166666666666
20.0,0.11247810001981755,0.1572339451534951,0.9539166666666666
21.0,0.10979045816262563,0.1595446849836314,0.9541666666666667
22.0,0.10925927674770355,0.1563612585193775,0.9539166666666666
23.0,0.10909713908284903,0.1547585829715938,0.9551666666666667
24.0,0.10744588159956038,0.15660694826572658,0.9545
