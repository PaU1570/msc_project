epoch,train_loss,val_loss,val_acc
0.0,1.609066797574361,0.6776087349082561,0.7699166666666667
1.0,0.47779628485441206,0.3735593736488768,0.8895833333333333
2.0,0.3334573246339957,0.30564602024536186,0.9085
3.0,0.2871167883922656,0.2948576318536033,0.91175
4.0,0.25218237898747126,0.26027617227048316,0.9221666666666667
5.0,0.22547266605496408,0.25421578114099325,0.9266666666666666
6.0,0.21178618338207403,0.2384157255093785,0.9299166666666666
7.0,0.19236549778530995,0.218069494890168,0.9351666666666667
8.0,0.1831813770160079,0.21902101536459745,0.9338333333333333
9.0,0.17298152018338442,0.2054158824278002,0.9383333333333334
10.0,0.15370518790185453,0.196276885170014,0.9414166666666667
11.0,0.15034652475019297,0.1981639714634165,0.9435
12.0,0.1444912369797627,0.18860876676626503,0.94375
13.0,0.13968891677260398,0.18772261075556596,0.9460833333333334
14.0,0.13467678331335386,0.17983511124955529,0.9465833333333333
15.0,0.1315960069547097,0.1717257882924156,0.9486666666666667
16.0,0.12712601735442877,0.1785820686912283,0.94775
17.0,0.12522478439534704,0.17501986989791088,0.94875
18.0,0.12211460619295637,0.17182926372922164,0.9490833333333333
19.0,0.11882769436637561,0.1609992981056108,0.9503333333333334
20.0,0.11203420880436897,0.16173130955963216,0.9516666666666667
21.0,0.10904760146637757,0.16294574161912215,0.94925
22.0,0.1061222221677502,0.16858334736304081,0.9498333333333333
23.0,0.10532174920352796,0.15996038514447022,0.9495
24.0,0.10525223830963175,0.16183729574797637,0.9524166666666667
