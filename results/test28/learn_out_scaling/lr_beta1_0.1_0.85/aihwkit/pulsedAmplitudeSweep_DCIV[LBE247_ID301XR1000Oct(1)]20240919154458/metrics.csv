epoch,train_loss,val_loss,val_acc
0.0,2.375866007645925,2.301030732215719,0.11108333333333334
1.0,0.9505232764283816,0.387124434826856,0.88325
2.0,0.2679109607984622,0.23218793219866904,0.9304166666666667
3.0,0.1944525611102581,0.19518553693481583,0.941
4.0,0.15620698032403985,0.17467571558193007,0.9471666666666667
5.0,0.13227621181309224,0.1649544196242982,0.9531666666666667
6.0,0.11411608806749185,0.1514326476571249,0.9555
7.0,0.10253692767520746,0.14319196238400453,0.95875
8.0,0.09182463289486865,0.135967946257145,0.9614166666666667
9.0,0.08222069411491975,0.14215364532812716,0.9606666666666667
10.0,0.06381407094180273,0.13782166167994606,0.9608333333333333
11.0,0.05927802701449643,0.1293368830353002,0.9651666666666666
12.0,0.05441536376128594,0.13244566293136079,0.9661666666666666
13.0,0.050314991999339934,0.13230560900410637,0.9655833333333333
14.0,0.046799830523940426,0.1359659611207849,0.9646666666666667
15.0,0.04449360359351461,0.12848634099800813,0.96625
16.0,0.04043927412837123,0.1511576119147766,0.9640833333333333
17.0,0.03815985647076741,0.14521043827575186,0.9664166666666667
18.0,0.03437279443729979,0.14078740077805357,0.9666666666666667
19.0,0.0325017002990935,0.1489529234485359,0.9660833333333333
20.0,0.028982738165184856,0.14744193172489448,0.9676666666666667
21.0,0.027363160349351042,0.14614983650167135,0.9664166666666667
22.0,0.025305245196912438,0.15160832565549967,0.9684166666666667
23.0,0.024786627922895908,0.1524794704337763,0.9678333333333333
24.0,0.023317755033824748,0.1630714804264147,0.9651666666666666
