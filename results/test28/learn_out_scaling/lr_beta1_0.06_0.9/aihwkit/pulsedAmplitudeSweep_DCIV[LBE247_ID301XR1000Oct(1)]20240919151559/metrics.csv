epoch,train_loss,val_loss,val_acc
0.0,1.422684678097566,0.47553714325136326,0.8580833333333333
1.0,0.33815126898884773,0.28009807009329185,0.9179166666666667
2.0,0.2350775577177604,0.22711948083436234,0.93275
3.0,0.19118559069683155,0.19114985418050212,0.9429166666666666
4.0,0.1574860166311264,0.1808878047431403,0.9475
5.0,0.14098770933101576,0.1624606877188892,0.9495833333333333
6.0,0.12332192004844546,0.15632114603996594,0.9545
7.0,0.11126386914526423,0.14708361973827508,0.95525
8.0,0.10128146611216167,0.14282606162646033,0.9573333333333334
9.0,0.09191253380974133,0.13633426258023432,0.9608333333333333
10.0,0.0799864373098438,0.12861643968387804,0.9628333333333333
11.0,0.07556540352168183,0.13139209539401642,0.9631666666666666
12.0,0.07121450550698985,0.13244648789739275,0.9618333333333333
13.0,0.06968153080592553,0.12839847337949942,0.9634166666666667
14.0,0.06662208439068248,0.1371401575161144,0.9624166666666667
15.0,0.06317402917534734,0.1276378025142278,0.9639166666666666
16.0,0.06179887201264501,0.12689184451703617,0.96475
17.0,0.05894287779477114,0.12949144461519144,0.9656666666666667
18.0,0.056566713709539425,0.1266965741995088,0.9645
19.0,0.05415748843752469,0.12387788290296622,0.96425
20.0,0.04903768243229327,0.12975882285799673,0.9655833333333333
21.0,0.0474528011342433,0.1261495690126507,0.9676666666666667
22.0,0.04631351880977551,0.12930366083821085,0.9650833333333333
23.0,0.04706671598181129,0.12952293062017875,0.9664166666666667
24.0,0.04423529319635903,0.13557882678194685,0.9655
