epoch,train_loss,val_loss,val_acc
0.0,1.4538227843840916,0.4112399655612225,0.87675
1.0,0.30901700965066753,0.27011002841940585,0.92125
2.0,0.2156177811374267,0.21013834161010195,0.9373333333333334
3.0,0.17059597539156676,0.1829742868728143,0.9471666666666667
4.0,0.14473174916456144,0.16738598184422293,0.9500833333333333
5.0,0.12530502926185727,0.15685749189442696,0.9556666666666667
6.0,0.11042639263346792,0.14641791150627775,0.9590833333333333
7.0,0.09636718286511799,0.134567041168029,0.9616666666666667
8.0,0.08696279972108702,0.1358611397123202,0.9611666666666666
9.0,0.08021521916612982,0.12850567333380433,0.9626666666666667
10.0,0.06860250324911127,0.12600290291060873,0.965
11.0,0.06424362908117473,0.1254622781936555,0.9640833333333333
12.0,0.05985702231572941,0.12345210160128772,0.9661666666666666
13.0,0.05713866887179514,0.12311463139361721,0.96575
14.0,0.05339544978970662,0.12617780259523065,0.96425
15.0,0.051295307596796194,0.12919743147435936,0.9670833333333333
16.0,0.04868343508678178,0.13319205267396952,0.9654166666666667
17.0,0.047494221976725384,0.12036298775421257,0.966
18.0,0.04326517333455073,0.12736197828099707,0.967
19.0,0.04428510828898288,0.12897735993635465,0.9649166666666666
20.0,0.03757316679065116,0.12323485190938029,0.9684166666666667
21.0,0.03548546490736772,0.1280768475968371,0.9664166666666667
22.0,0.03438770064207104,0.13070684460120552,0.9675
23.0,0.03413769154068238,0.13300936816673864,0.96775
24.0,0.03302415956242476,0.13344152929803774,0.9674166666666667
