epoch,train_loss,val_loss,val_acc
0.0,1.2197907988627752,0.4494648850820166,0.8670833333333333
1.0,0.34892822060982387,0.2902902998426493,0.9140833333333334
2.0,0.2530149673918883,0.24495689345008514,0.9294166666666667
3.0,0.2078043186912934,0.21799915509813644,0.9369166666666666
4.0,0.17826635421067477,0.19780510922576836,0.9435833333333333
5.0,0.15625837439546983,0.1734370871724442,0.9500833333333333
6.0,0.14043486513445774,0.17377315806423096,0.951
7.0,0.1292557288768391,0.16232503975365073,0.95225
8.0,0.12114786572009326,0.16329576423827638,0.9536666666666667
9.0,0.11027573733528455,0.1490550819744772,0.9555
10.0,0.09839219113749763,0.14640933109764406,0.9591666666666666
11.0,0.0947681486022969,0.14407903916063777,0.9601666666666666
12.0,0.09238031270789604,0.13829048984545342,0.9598333333333333
13.0,0.0873907754054914,0.13976499434818138,0.9595
14.0,0.0857160522332415,0.14011141423512488,0.96
15.0,0.08296752737338345,0.14320352135047792,0.9601666666666666
16.0,0.08088756102509796,0.13610061405702156,0.9620833333333333
17.0,0.07670264443010091,0.13364738978425714,0.9623333333333334
18.0,0.07376774569973349,0.13716910518904,0.96125
19.0,0.07218398098368198,0.13089920788448542,0.9616666666666667
20.0,0.06817697074729949,0.1274400153643194,0.9644166666666667
21.0,0.06641336717891197,0.13256128214577095,0.9626666666666667
22.0,0.06442318739462644,0.12795367473340097,0.9644166666666667
23.0,0.06444716579529146,0.12723212357253788,0.9645
24.0,0.0632655867212452,0.12484764971552377,0.9663333333333334
