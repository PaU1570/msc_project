epoch,train_loss,val_loss,val_acc
0.0,1.4151071293950082,0.4450689422640395,0.86575
1.0,0.34036640815933544,0.2971416186699842,0.9119166666666667
2.0,0.2357371237327655,0.2339403388744339,0.9301666666666667
3.0,0.1936449260065953,0.19181736953001707,0.942
4.0,0.16297420079012712,0.17611879872237432,0.9479166666666666
5.0,0.14283713212609292,0.16181037403603502,0.95225
6.0,0.12316887963439027,0.14902074006881486,0.9553333333333334
7.0,0.10942362142230073,0.14291588995268845,0.9563333333333334
8.0,0.09981506134942174,0.13592875605211296,0.9596666666666667
9.0,0.09302700897927085,0.1303693159047435,0.9615833333333333
10.0,0.0804074810994789,0.12582524681087345,0.963
11.0,0.0775769234681502,0.12709019965729973,0.9636666666666667
12.0,0.07385738390653084,0.12435138659759801,0.96475
13.0,0.06954677487351,0.12552245789172842,0.9645833333333333
14.0,0.0675506266686134,0.12311615874158575,0.9649166666666666
15.0,0.0668063675177594,0.12064714734244378,0.9659166666666666
16.0,0.06202675077846895,0.1275952306050966,0.966
17.0,0.06010253410289685,0.12319506568205048,0.9665
18.0,0.05895468760623286,0.1220001834246548,0.9669166666666666
19.0,0.056003514038398865,0.12011450309395552,0.9666666666666667
20.0,0.05152837044497331,0.1251013902018461,0.96625
21.0,0.049455644910223785,0.12082983208745916,0.9674166666666667
22.0,0.04811503558823218,0.12392906917437435,0.9681666666666666
23.0,0.04620550030159454,0.12364052219856332,0.9684166666666667
24.0,0.0469075899895591,0.12268968544494202,0.9694166666666667
