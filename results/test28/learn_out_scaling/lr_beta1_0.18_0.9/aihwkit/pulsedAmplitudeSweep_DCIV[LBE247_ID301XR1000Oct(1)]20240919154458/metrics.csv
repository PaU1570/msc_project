epoch,train_loss,val_loss,val_acc
0.0,2.3211915086110433,1.5579843717686674,0.48141666666666666
1.0,1.0744158093531926,0.5162074372489401,0.8499166666666667
2.0,0.36907936973373096,0.29813631120672884,0.9101666666666667
3.0,0.27604948995510736,0.25535453705394523,0.926
4.0,0.221014921421806,0.2258179615786735,0.93175
5.0,0.19991617040832838,0.2281742811480418,0.9319166666666666
6.0,0.19224347870548567,0.21352259265853368,0.9358333333333333
7.0,0.17407733658701183,0.20975048387264636,0.9376666666666666
8.0,0.1671607990587751,0.19661178030668103,0.9408333333333333
9.0,0.15711409621064862,0.18083891609406216,0.9490833333333333
10.0,0.12952271346499522,0.1613530708734501,0.9511666666666667
11.0,0.11798473937064409,0.15864474571092016,0.9529166666666666
12.0,0.110770356160899,0.1507512137412708,0.9554166666666667
13.0,0.10231448924417297,0.15257068228055823,0.9569166666666666
14.0,0.09792272609906892,0.15330605967307187,0.9573333333333334
15.0,0.09012674929294735,0.14218023809743055,0.9585
16.0,0.08334670003565649,0.14085230380891167,0.9574166666666667
17.0,0.07798786205581079,0.14509390308422612,0.9584166666666667
18.0,0.0755016802009195,0.14253909463320483,0.95925
19.0,0.0705078605444481,0.1506552875408546,0.9591666666666666
20.0,0.06194516592565924,0.1395210395666196,0.9606666666666667
21.0,0.0583713281788708,0.14497238259881418,0.9615833333333333
22.0,0.05540673694581104,0.15088546800704555,0.96175
23.0,0.052505135364132004,0.15459949192293782,0.9613333333333334
24.0,0.05148276034525285,0.15399513546714283,0.9629166666666666
