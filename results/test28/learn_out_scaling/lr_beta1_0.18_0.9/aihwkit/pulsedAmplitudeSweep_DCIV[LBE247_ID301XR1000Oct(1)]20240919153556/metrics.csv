epoch,train_loss,val_loss,val_acc
0.0,1.7318795128266016,0.696921244105126,0.7670833333333333
1.0,0.38923657607038814,0.3134164181637003,0.9095833333333333
2.0,0.24370697449644407,0.229364704003835,0.9323333333333333
3.0,0.19209288104375202,0.19618123790566275,0.9446666666666667
4.0,0.16180736619606614,0.18588880919157824,0.9474166666666667
5.0,0.15012085474158327,0.1744358729313504,0.9504166666666667
6.0,0.1333239426376919,0.16788243844193665,0.9528333333333333
7.0,0.12371210806195934,0.16370220262398746,0.954
8.0,0.1173421397600323,0.16712686842049848,0.9531666666666667
9.0,0.10844596221422155,0.167014561801594,0.9531666666666667
10.0,0.09106100002862513,0.15429217278204382,0.9563333333333334
11.0,0.08615902777016163,0.14221074175525536,0.96025
12.0,0.08075637615347903,0.14709912144648346,0.9594166666666667
13.0,0.07404747522591303,0.1410250334921194,0.96125
14.0,0.07200613905768842,0.14414602251069503,0.96125
15.0,0.06867049968335777,0.13763086296905308,0.9630833333333333
16.0,0.06191766552285602,0.13791837986741967,0.96275
17.0,0.06016890758105243,0.14424743451564473,0.9614166666666667
18.0,0.058742957952897995,0.1425434537937845,0.9639166666666666
19.0,0.05642142103333026,0.13949473187490863,0.9633333333333334
20.0,0.04952382107327382,0.144128331094683,0.9630833333333333
21.0,0.04766201126637558,0.14515422013689802,0.9636666666666667
22.0,0.046244869862372674,0.14809016115434637,0.9635
23.0,0.04515626080341947,0.14844819895323721,0.9624166666666667
24.0,0.044202635237171,0.14955988917914664,0.9626666666666667
