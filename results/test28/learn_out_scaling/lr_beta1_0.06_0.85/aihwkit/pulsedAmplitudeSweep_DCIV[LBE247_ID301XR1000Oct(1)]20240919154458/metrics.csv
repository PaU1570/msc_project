epoch,train_loss,val_loss,val_acc
0.0,2.3072081321080526,2.3070116550364395,0.09608333333333334
1.0,1.1043488396604857,0.4036038366562508,0.87925
2.0,0.28532708923518657,0.25097793384276806,0.9251666666666667
3.0,0.20698386061936616,0.21108406338285893,0.9365
4.0,0.16600434669603903,0.1789985865631953,0.9475833333333333
5.0,0.1382885317156712,0.17111954613132996,0.9493333333333334
6.0,0.12151932336390019,0.15187446517433892,0.9559166666666666
7.0,0.1089538226481527,0.14512283027053197,0.9584166666666667
8.0,0.09521573048519591,0.14235452830078119,0.9589166666666666
9.0,0.0854142230618745,0.13579624832825773,0.96175
10.0,0.07340752549034854,0.13217943972174792,0.9619166666666666
11.0,0.06888507690094411,0.12859153636344808,0.9640833333333333
12.0,0.06542401287704706,0.12817377132423063,0.9643333333333334
13.0,0.0605664662035803,0.1310142306189865,0.9643333333333334
14.0,0.05772060827941944,0.13007544965156295,0.9646666666666667
15.0,0.05535301689306895,0.13440390050837256,0.9648333333333333
16.0,0.05187662301181505,0.13330315190560602,0.96425
17.0,0.04920640791238596,0.13184232770296883,0.9671666666666666
18.0,0.04728911281509014,0.1344458267967058,0.9638333333333333
19.0,0.043456957390842335,0.13541976345376053,0.96625
20.0,0.037553587472609555,0.13913636333358653,0.9668333333333333
21.0,0.037434664843371136,0.14131201089835388,0.9660833333333333
22.0,0.03674779171589762,0.13687545575815788,0.9655833333333333
23.0,0.034867317385079026,0.13758674176394978,0.9675833333333334
24.0,0.03371474113016545,0.1356984071948744,0.9666666666666667
