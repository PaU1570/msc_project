epoch,train_loss,val_loss,val_acc
0.0,1.1765899014075598,0.40724032506980795,0.8799166666666667
1.0,0.3023880776862303,0.2665091032122678,0.9211666666666667
2.0,0.22675629686315854,0.2294168298311056,0.9316666666666666
3.0,0.18553457909077406,0.1902532911502776,0.9451666666666667
4.0,0.16309039709468684,0.17802025901867038,0.9465833333333333
5.0,0.1460529285656909,0.16172312154494067,0.9506666666666667
6.0,0.14209597209468483,0.15827514065746615,0.9535
7.0,0.11934420531305175,0.14951280259745234,0.9553333333333334
8.0,0.1088233595068256,0.13646951899368395,0.9596666666666667
9.0,0.10159210980994006,0.1363050312328925,0.9593333333333334
10.0,0.0872029478996992,0.13445770285250816,0.96225
11.0,0.08208816870550315,0.13430592530788457,0.9611666666666666
12.0,0.0788044529541706,0.12937141998492657,0.9633333333333334
13.0,0.07635657300427556,0.12756255944259465,0.96375
14.0,0.07247703489723305,0.13066983806400342,0.96375
15.0,0.0700464719934389,0.13231669475096575,0.9621666666666666
16.0,0.06865553273136417,0.13579633717791753,0.9645
17.0,0.06735557501297444,0.13547996831983525,0.9629166666666666
18.0,0.06365669127802054,0.1213305530762498,0.9653333333333334
19.0,0.06000856597706054,0.13281942316345832,0.96525
20.0,0.054881558737407125,0.1268806049013213,0.96575
21.0,0.05415459948560844,0.12402062015694645,0.9679166666666666
22.0,0.052135080125182864,0.12106637970390828,0.9665
23.0,0.05211885496539374,0.12671196183122874,0.9661666666666666
24.0,0.05035517011055102,0.12284532666424329,0.9671666666666666
