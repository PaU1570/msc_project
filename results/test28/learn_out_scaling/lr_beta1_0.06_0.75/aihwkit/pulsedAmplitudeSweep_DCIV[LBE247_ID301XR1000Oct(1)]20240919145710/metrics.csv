epoch,train_loss,val_loss,val_acc
0.0,1.1947142922679583,0.4178469868257959,0.87725
1.0,0.3207258831262588,0.2650499876113014,0.9210833333333334
2.0,0.23345760419468084,0.22917348059250953,0.9333333333333333
3.0,0.19192617739240328,0.19534678893916785,0.9410833333333334
4.0,0.16021563397472102,0.17162666418292422,0.9466666666666667
5.0,0.14462099671984713,0.16582068745443163,0.9498333333333333
6.0,0.1313001159802079,0.1636357172887693,0.9504166666666667
7.0,0.11956919816633066,0.1554927059469071,0.9538333333333333
8.0,0.10910161411762237,0.14148007084595712,0.9589166666666666
9.0,0.1000144215474526,0.13498032298137216,0.95975
10.0,0.08866683464528372,0.13203680874442958,0.961
11.0,0.0836287805022051,0.13213400533819136,0.9611666666666666
12.0,0.08135667333131036,0.12928608476501355,0.96225
13.0,0.07859831831045448,0.1274978212586188,0.9644166666666667
14.0,0.07508516772463918,0.13060993453527384,0.9643333333333334
15.0,0.07132553878736993,0.12783269937387964,0.9640833333333333
16.0,0.06870300725381821,0.12628674618602592,0.9645833333333333
17.0,0.06590472338628024,0.12639298797783224,0.96525
18.0,0.06483757103482882,0.1244916781941627,0.9646666666666667
19.0,0.060502846303706365,0.12390797857834185,0.966
20.0,0.05534295477562894,0.12337508056550583,0.9663333333333334
21.0,0.054947740693887075,0.12309816368840674,0.9661666666666666
22.0,0.054404228067491206,0.12070808691676072,0.9659166666666666
23.0,0.05327023938174049,0.12426631594141152,0.9645833333333333
24.0,0.05208681689342484,0.12372095130279938,0.9669166666666666
