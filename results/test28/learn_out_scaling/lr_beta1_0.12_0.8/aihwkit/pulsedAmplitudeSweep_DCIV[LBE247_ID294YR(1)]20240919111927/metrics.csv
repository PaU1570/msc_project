epoch,train_loss,val_loss,val_acc
0.0,2.0189687356154122,0.8158056380900931,0.7354166666666667
1.0,0.5258199791113536,0.40516861504379736,0.8765833333333334
2.0,0.34592992225289343,0.3273249919268679,0.9044166666666666
3.0,0.283322012146314,0.28825014011260675,0.9161666666666667
4.0,0.2505242295960585,0.25718119686984636,0.9258333333333333
5.0,0.2197129442691803,0.23506279172811737,0.93125
6.0,0.19596065687636535,0.22526694162491154,0.93475
7.0,0.18285228711863358,0.20815406790240965,0.9421666666666667
8.0,0.1725259287680189,0.1918726906457797,0.9449166666666666
9.0,0.16231646304329236,0.19647941725487086,0.9409166666666666
10.0,0.14436167375991743,0.17964455140556426,0.9459166666666666
11.0,0.13971569366008044,0.17494902719168903,0.95025
12.0,0.13430835074931383,0.1743112473570286,0.9490833333333333
13.0,0.1301680169987182,0.16682138694252105,0.95
14.0,0.12540675203688442,0.16438959865890285,0.9514166666666667
15.0,0.12326001113653183,0.15952913520580275,0.9518333333333333
16.0,0.1189751219364504,0.1643533215045612,0.95125
17.0,0.11639567620679736,0.1595645676010308,0.9504166666666667
18.0,0.11342202240601182,0.16759869130328298,0.9511666666666667
19.0,0.1104745896346867,0.15936721650328725,0.9546666666666667
20.0,0.10322709988119702,0.14699528823071656,0.9564166666666667
21.0,0.10168290420807898,0.14895884796699627,0.9553333333333334
22.0,0.0996353488198171,0.14409348527167706,0.9570833333333333
23.0,0.0981803324110806,0.14378097271447646,0.95625
24.0,0.09737579778085152,0.14783791618600012,0.9565
