epoch,train_loss,val_loss,val_acc
0.0,1.6068888957103094,0.7284475355706317,0.7399166666666667
1.0,0.6447807025114696,0.5611883054705377,0.80075
2.0,0.4710304141541322,0.35194110394792355,0.8913333333333333
3.0,0.31752674738566083,0.31825533739112793,0.9030833333333333
4.0,0.26941430857777593,0.2898393534520205,0.9143333333333333
5.0,0.23992432381709417,0.24790486291130173,0.9251666666666667
6.0,0.22719031335413456,0.25268605953835427,0.9254166666666667
7.0,0.22260847793022792,0.236786667237732,0.9293333333333333
8.0,0.20165593573451043,0.22374122074626862,0.9328333333333333
9.0,0.1936701855013768,0.22477227633700092,0.9321666666666667
10.0,0.1751056663642327,0.20391217289254704,0.9403333333333334
11.0,0.16075195632626613,0.18530079147758635,0.9454166666666667
12.0,0.15323653837355475,0.1856456140769606,0.94325
13.0,0.14488941972951094,0.17857024913772623,0.9480833333333333
14.0,0.14016909693554044,0.18641877814414018,0.9446666666666667
15.0,0.1345329170115292,0.17304428415174813,0.9483333333333334
16.0,0.12890244687721134,0.1753416379339042,0.9505833333333333
17.0,0.12316331623246272,0.1688699666212531,0.9514166666666667
18.0,0.11918227511582276,0.16440746683548105,0.9518333333333333
19.0,0.11309810180403292,0.16099066276380675,0.9520833333333333
20.0,0.10324766595847905,0.15831298476947037,0.9538333333333333
21.0,0.09924187163511912,0.15028481283026965,0.9551666666666667
22.0,0.09715726916491986,0.15166783538904596,0.9554166666666667
23.0,0.09410369206964969,0.15464923104786493,0.95525
24.0,0.09303499466180801,0.1548539608905211,0.95725
