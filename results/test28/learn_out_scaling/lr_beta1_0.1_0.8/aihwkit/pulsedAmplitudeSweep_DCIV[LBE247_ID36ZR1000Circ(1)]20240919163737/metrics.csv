epoch,train_loss,val_loss,val_acc
0.0,2.2336683111190796,1.2446289268579889,0.5606666666666666
1.0,0.5901532437006632,0.39882926650820893,0.8776666666666667
2.0,0.32587635108828544,0.29500458159662307,0.9114166666666667
3.0,0.2563905973434448,0.25110439064496376,0.9241666666666667
4.0,0.2221268019179503,0.2244395128986303,0.93325
5.0,0.193053593814373,0.2021737737541503,0.9401666666666667
6.0,0.17688600046932698,0.1901054654983764,0.9446666666666667
7.0,0.16043627713869016,0.17754753363972647,0.9454166666666667
8.0,0.1481266795732081,0.1812163379756694,0.947
9.0,0.1383065106595556,0.16963485495603464,0.95075
10.0,0.12533248002578815,0.15731956766165317,0.9514166666666667
11.0,0.11852645761271317,0.156522033696479,0.9535833333333333
12.0,0.1131634639253219,0.15680243771404345,0.9548333333333333
13.0,0.11130374627249937,0.15455649562298934,0.9550833333333333
14.0,0.10598141780557732,0.15071046688257062,0.9549166666666666
15.0,0.10283345637470484,0.1525296473459519,0.9553333333333334
16.0,0.10007393411360681,0.1475954220650044,0.9570833333333333
17.0,0.09796072090106706,0.15601869923696715,0.9568333333333333
18.0,0.09606234857439995,0.14193611067937725,0.9598333333333333
19.0,0.09209021172098195,0.14064850439713833,0.9603333333333334
20.0,0.08448981702079375,0.14087367210874058,0.9619166666666666
21.0,0.08341756597999483,0.1376132860561793,0.9605833333333333
22.0,0.08162826755782589,0.13684590067962146,0.96175
23.0,0.08011436986302337,0.13552905224818498,0.9626666666666667
24.0,0.07864748177677393,0.14032484917960902,0.9623333333333334
