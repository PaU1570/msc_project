epoch,train_loss,val_loss,val_acc
0.0,1.7814998015562693,0.6833270022526701,0.7781666666666667
1.0,0.4390547965268294,0.33818267147116204,0.8975833333333333
2.0,0.2822131829559803,0.2591880378016132,0.923
3.0,0.22209013180434703,0.22984179649303885,0.9305833333333333
4.0,0.1938259166503946,0.2180737898427438,0.9343333333333333
5.0,0.17750036773085595,0.19882541611552873,0.9398333333333333
6.0,0.1614455328161518,0.184815435234378,0.9478333333333333
7.0,0.14507960745692253,0.16653609867802166,0.9520833333333333
8.0,0.1363777180624505,0.1647187778478528,0.9528333333333333
9.0,0.12727751701449355,0.16321289756315502,0.9534166666666667
10.0,0.1137521816532438,0.16406920233721586,0.9546666666666667
11.0,0.10809570016277333,0.15154558201221394,0.9555833333333333
12.0,0.10559982356180747,0.15686845757622034,0.9553333333333334
13.0,0.10058767920173704,0.15875909707578334,0.9564166666666667
14.0,0.09640067905001343,0.1664307753709046,0.9565833333333333
15.0,0.09228518827818334,0.15051541348641856,0.9575
16.0,0.09027769404401381,0.14575641338733283,0.95825
17.0,0.08732593169187507,0.1432454851059679,0.9585833333333333
18.0,0.08264566688487927,0.14700562036299009,0.9570833333333333
19.0,0.08044153192204734,0.14645100969008784,0.962
20.0,0.07213006202876568,0.14193923994056643,0.9613333333333334
21.0,0.0699660028317012,0.1364067700094583,0.9624166666666667
22.0,0.06997484565045063,0.136561497929506,0.9629166666666666
23.0,0.06742995056447884,0.13900924605153936,0.9626666666666667
24.0,0.06618682914413512,0.13896961177283146,0.96275
